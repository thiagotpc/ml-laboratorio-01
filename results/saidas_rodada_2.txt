
C:\Projetos\ml-laboratorio-01>py knn.py features_10x10.txt 1 EU 
Loading data...
Spliting data...
Using n_neighbors=1
Using metric=euclidean
Fitting knn
Predicting...
Accuracy:  0.9
[[94  0  0  1  0  2  0  0  0  0]
 [ 0 94  0  0  0  0  0  0  0  1]
 [ 1  3 98  1  0  0  1  4  2  1]
 [ 1  0  0 95  1  1  0  2  2  1]
 [ 0  9  0  0 80  0  1  0  0  5]
 [ 0  1  0  7  0 89  0  0  0  0]
 [ 1  6  0  0  0  1 98  0  0  0]
 [ 0  3  1  0  1  0  0 88  0  4]
 [ 0  3  0  5  0  3  1  3 68  4]
 [ 0  1  0  0  2  0  0 12  1 96]]
              precision    recall  f1-score   support

           0       0.97      0.97      0.97        97
           1       0.78      0.99      0.87        95
           2       0.99      0.88      0.93       111
           3       0.87      0.92      0.90       103
           4       0.95      0.84      0.89        95
           5       0.93      0.92      0.92        97
           6       0.97      0.92      0.95       106
           7       0.81      0.91      0.85        97
           8       0.93      0.78      0.85        87
           9       0.86      0.86      0.86       112

    accuracy                           0.90      1000
   macro avg       0.91      0.90      0.90      1000
weighted avg       0.91      0.90      0.90      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_10x10.txt 1 MA 
Loading data...
Spliting data...
Using n_neighbors=1
Using metric=manhattan
Fitting knn
Predicting...
Accuracy:  0.9
[[94  0  0  1  0  2  0  0  0  0]
 [ 0 94  0  0  0  0  0  0  0  1]
 [ 1  3 98  1  0  0  1  4  2  1]
 [ 1  0  0 95  1  1  0  2  2  1]
 [ 0  9  0  0 80  0  1  0  0  5]
 [ 0  1  0  7  0 89  0  0  0  0]
 [ 1  6  0  0  0  1 98  0  0  0]
 [ 0  3  1  0  1  0  0 88  0  4]
 [ 0  3  0  5  0  3  1  3 68  4]
 [ 0  1  0  0  2  0  0 12  1 96]]
              precision    recall  f1-score   support

           0       0.97      0.97      0.97        97
           1       0.78      0.99      0.87        95
           2       0.99      0.88      0.93       111
           3       0.87      0.92      0.90       103
           4       0.95      0.84      0.89        95
           5       0.93      0.92      0.92        97
           6       0.97      0.92      0.95       106
           7       0.81      0.91      0.85        97
           8       0.93      0.78      0.85        87
           9       0.86      0.86      0.86       112

    accuracy                           0.90      1000
   macro avg       0.91      0.90      0.90      1000
weighted avg       0.91      0.90      0.90      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_10x10.txt 1 MI 
Loading data...
Spliting data...
Using n_neighbors=1
Using metric=minkowski
Fitting knn
Predicting...
Accuracy:  0.9
[[94  0  0  1  0  2  0  0  0  0]
 [ 0 94  0  0  0  0  0  0  0  1]
 [ 1  3 98  1  0  0  1  4  2  1]
 [ 1  0  0 95  1  1  0  2  2  1]
 [ 0  9  0  0 80  0  1  0  0  5]
 [ 0  1  0  7  0 89  0  0  0  0]
 [ 1  6  0  0  0  1 98  0  0  0]
 [ 0  3  1  0  1  0  0 88  0  4]
 [ 0  3  0  5  0  3  1  3 68  4]
 [ 0  1  0  0  2  0  0 12  1 96]]
              precision    recall  f1-score   support

           0       0.97      0.97      0.97        97
           1       0.78      0.99      0.87        95
           2       0.99      0.88      0.93       111
           3       0.87      0.92      0.90       103
           4       0.95      0.84      0.89        95
           5       0.93      0.92      0.92        97
           6       0.97      0.92      0.95       106
           7       0.81      0.91      0.85        97
           8       0.93      0.78      0.85        87
           9       0.86      0.86      0.86       112

    accuracy                           0.90      1000
   macro avg       0.91      0.90      0.90      1000
weighted avg       0.91      0.90      0.90      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_10x10.txt 3 EU 
Loading data...
Spliting data...
Using n_neighbors=3
Using metric=euclidean
Fitting knn
Predicting...
Accuracy:  0.894
[[ 94   1   0   0   0   1   1   0   0   0]
 [  0  93   0   0   0   1   0   0   0   1]
 [  1   4 100   0   1   0   1   3   1   0]
 [  2   0   3  95   0   0   0   0   2   1]
 [  0  11   1   0  80   0   0   0   0   3]
 [  1   1   0   5   0  89   0   0   1   0]
 [  1   7   0   0   0   0  98   0   0   0]
 [  0   8   1   0   0   1   0  81   0   6]
 [  0   5   0   4   1   1   0   4  69   3]
 [  0   2   0   0   4   0   0  11   0  95]]
              precision    recall  f1-score   support

           0       0.95      0.97      0.96        97
           1       0.70      0.98      0.82        95
           2       0.95      0.90      0.93       111
           3       0.91      0.92      0.92       103
           4       0.93      0.84      0.88        95
           5       0.96      0.92      0.94        97
           6       0.98      0.92      0.95       106
           7       0.82      0.84      0.83        97
           8       0.95      0.79      0.86        87
           9       0.87      0.85      0.86       112

    accuracy                           0.89      1000
   macro avg       0.90      0.89      0.89      1000
weighted avg       0.90      0.89      0.90      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_10x10.txt 3 MA 
Loading data...
Spliting data...
Using n_neighbors=3
Using metric=manhattan
Fitting knn
Predicting...
Accuracy:  0.894
[[ 94   1   0   0   0   1   1   0   0   0]
 [  0  93   0   0   0   1   0   0   0   1]
 [  1   4 100   0   1   0   1   3   1   0]
 [  2   0   3  95   0   0   0   0   2   1]
 [  0  11   1   0  80   0   0   0   0   3]
 [  1   1   0   5   0  89   0   0   1   0]
 [  1   7   0   0   0   0  98   0   0   0]
 [  0   8   1   0   0   1   0  81   0   6]
 [  0   5   0   4   1   1   0   4  69   3]
 [  0   2   0   0   4   0   0  11   0  95]]
              precision    recall  f1-score   support

           0       0.95      0.97      0.96        97
           1       0.70      0.98      0.82        95
           2       0.95      0.90      0.93       111
           3       0.91      0.92      0.92       103
           4       0.93      0.84      0.88        95
           5       0.96      0.92      0.94        97
           6       0.98      0.92      0.95       106
           7       0.82      0.84      0.83        97
           8       0.95      0.79      0.86        87
           9       0.87      0.85      0.86       112

    accuracy                           0.89      1000
   macro avg       0.90      0.89      0.89      1000
weighted avg       0.90      0.89      0.90      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_10x10.txt 3 MI 
Loading data...
Spliting data...
Using n_neighbors=3
Using metric=minkowski
Fitting knn
Predicting...
Accuracy:  0.894
[[ 94   1   0   0   0   1   1   0   0   0]
 [  0  93   0   0   0   1   0   0   0   1]
 [  1   4 100   0   1   0   1   3   1   0]
 [  2   0   3  95   0   0   0   0   2   1]
 [  0  11   1   0  80   0   0   0   0   3]
 [  1   1   0   5   0  89   0   0   1   0]
 [  1   7   0   0   0   0  98   0   0   0]
 [  0   8   1   0   0   1   0  81   0   6]
 [  0   5   0   4   1   1   0   4  69   3]
 [  0   2   0   0   4   0   0  11   0  95]]
              precision    recall  f1-score   support

           0       0.95      0.97      0.96        97
           1       0.70      0.98      0.82        95
           2       0.95      0.90      0.93       111
           3       0.91      0.92      0.92       103
           4       0.93      0.84      0.88        95
           5       0.96      0.92      0.94        97
           6       0.98      0.92      0.95       106
           7       0.82      0.84      0.83        97
           8       0.95      0.79      0.86        87
           9       0.87      0.85      0.86       112

    accuracy                           0.89      1000
   macro avg       0.90      0.89      0.89      1000
weighted avg       0.90      0.89      0.90      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_10x10.txt 5 EU 
Loading data...
Spliting data...
Using n_neighbors=5
Using metric=euclidean
Fitting knn
Predicting...
Accuracy:  0.886
[[95  1  0  0  0  1  0  0  0  0]
 [ 0 94  0  0  0  0  0  0  0  1]
 [ 1  7 95  1  1  1  2  3  0  0]
 [ 0  1  1 97  0  1  0  1  2  0]
 [ 0 10  1  0 80  0  0  0  0  4]
 [ 0  1  0  7  0 87  2  0  0  0]
 [ 0  7  0  0  0  0 99  0  0  0]
 [ 0 12  0  0  0  1  0 79  1  4]
 [ 0  6  0  3  1  2  0  3 70  2]
 [ 0  3  0  0  6  0  0 13  0 90]]
              precision    recall  f1-score   support

           0       0.99      0.98      0.98        97
           1       0.66      0.99      0.79        95
           2       0.98      0.86      0.91       111
           3       0.90      0.94      0.92       103
           4       0.91      0.84      0.87        95
           5       0.94      0.90      0.92        97
           6       0.96      0.93      0.95       106
           7       0.80      0.81      0.81        97
           8       0.96      0.80      0.88        87
           9       0.89      0.80      0.85       112

    accuracy                           0.89      1000
   macro avg       0.90      0.89      0.89      1000
weighted avg       0.90      0.89      0.89      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_10x10.txt 5 MA 
Loading data...
Spliting data...
Using n_neighbors=5
Using metric=manhattan
Fitting knn
Predicting...
Accuracy:  0.886
[[95  1  0  0  0  1  0  0  0  0]
 [ 0 94  0  0  0  0  0  0  0  1]
 [ 1  7 95  1  1  1  2  3  0  0]
 [ 0  1  1 97  0  1  0  1  2  0]
 [ 0 10  1  0 80  0  0  0  0  4]
 [ 0  1  0  7  0 87  2  0  0  0]
 [ 0  7  0  0  0  0 99  0  0  0]
 [ 0 12  0  0  0  1  0 79  1  4]
 [ 0  6  0  3  1  2  0  3 70  2]
 [ 0  3  0  0  6  0  0 13  0 90]]
              precision    recall  f1-score   support

           0       0.99      0.98      0.98        97
           1       0.66      0.99      0.79        95
           2       0.98      0.86      0.91       111
           3       0.90      0.94      0.92       103
           4       0.91      0.84      0.87        95
           5       0.94      0.90      0.92        97
           6       0.96      0.93      0.95       106
           7       0.80      0.81      0.81        97
           8       0.96      0.80      0.88        87
           9       0.89      0.80      0.85       112

    accuracy                           0.89      1000
   macro avg       0.90      0.89      0.89      1000
weighted avg       0.90      0.89      0.89      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_10x10.txt 5 MI 
Loading data...
Spliting data...
Using n_neighbors=5
Using metric=minkowski
Fitting knn
Predicting...
Accuracy:  0.886
[[95  1  0  0  0  1  0  0  0  0]
 [ 0 94  0  0  0  0  0  0  0  1]
 [ 1  7 95  1  1  1  2  3  0  0]
 [ 0  1  1 97  0  1  0  1  2  0]
 [ 0 10  1  0 80  0  0  0  0  4]
 [ 0  1  0  7  0 87  2  0  0  0]
 [ 0  7  0  0  0  0 99  0  0  0]
 [ 0 12  0  0  0  1  0 79  1  4]
 [ 0  6  0  3  1  2  0  3 70  2]
 [ 0  3  0  0  6  0  0 13  0 90]]
              precision    recall  f1-score   support

           0       0.99      0.98      0.98        97
           1       0.66      0.99      0.79        95
           2       0.98      0.86      0.91       111
           3       0.90      0.94      0.92       103
           4       0.91      0.84      0.87        95
           5       0.94      0.90      0.92        97
           6       0.96      0.93      0.95       106
           7       0.80      0.81      0.81        97
           8       0.96      0.80      0.88        87
           9       0.89      0.80      0.85       112

    accuracy                           0.89      1000
   macro avg       0.90      0.89      0.89      1000
weighted avg       0.90      0.89      0.89      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_10x30.txt 1 EU 
Loading data...
Spliting data...
Using n_neighbors=1
Using metric=euclidean
Fitting knn
Predicting...
Accuracy:  0.921
[[ 94   0   0   0   0   1   1   1   0   0]
 [  0  94   0   0   0   0   0   0   0   1]
 [  0   1 103   1   1   0   0   4   1   0]
 [  0   1   0  99   0   1   0   1   1   0]
 [  0   9   0   0  81   1   1   0   0   3]
 [  0   1   0   6   0  89   0   0   1   0]
 [  1   5   0   0   1   0  99   0   0   0]
 [  0   1   1   0   1   0   0  89   0   5]
 [  0   3   0   0   1   3   0   1  77   2]
 [  0   2   0   0   1   0   0  13   0  96]]
              precision    recall  f1-score   support

           0       0.99      0.97      0.98        97
           1       0.80      0.99      0.89        95
           2       0.99      0.93      0.96       111
           3       0.93      0.96      0.95       103
           4       0.94      0.85      0.90        95
           5       0.94      0.92      0.93        97
           6       0.98      0.93      0.96       106
           7       0.82      0.92      0.86        97
           8       0.96      0.89      0.92        87
           9       0.90      0.86      0.88       112

    accuracy                           0.92      1000
   macro avg       0.93      0.92      0.92      1000
weighted avg       0.93      0.92      0.92      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_10x30.txt 1 MA 
Loading data...
Spliting data...
Using n_neighbors=1
Using metric=manhattan
Fitting knn
Predicting...
Accuracy:  0.921
[[ 94   0   0   0   0   1   1   1   0   0]
 [  0  94   0   0   0   0   0   0   0   1]
 [  0   1 103   1   1   0   0   4   1   0]
 [  0   1   0  99   0   1   0   1   1   0]
 [  0   9   0   0  81   1   1   0   0   3]
 [  0   1   0   6   0  89   0   0   1   0]
 [  1   5   0   0   1   0  99   0   0   0]
 [  0   1   1   0   1   0   0  89   0   5]
 [  0   3   0   0   1   3   0   1  77   2]
 [  0   2   0   0   1   0   0  13   0  96]]
              precision    recall  f1-score   support

           0       0.99      0.97      0.98        97
           1       0.80      0.99      0.89        95
           2       0.99      0.93      0.96       111
           3       0.93      0.96      0.95       103
           4       0.94      0.85      0.90        95
           5       0.94      0.92      0.93        97
           6       0.98      0.93      0.96       106
           7       0.82      0.92      0.86        97
           8       0.96      0.89      0.92        87
           9       0.90      0.86      0.88       112

    accuracy                           0.92      1000
   macro avg       0.93      0.92      0.92      1000
weighted avg       0.93      0.92      0.92      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_10x30.txt 1 MI 
Loading data...
Spliting data...
Using n_neighbors=1
Using metric=minkowski
Fitting knn
Predicting...
Accuracy:  0.921
[[ 94   0   0   0   0   1   1   1   0   0]
 [  0  94   0   0   0   0   0   0   0   1]
 [  0   1 103   1   1   0   0   4   1   0]
 [  0   1   0  99   0   1   0   1   1   0]
 [  0   9   0   0  81   1   1   0   0   3]
 [  0   1   0   6   0  89   0   0   1   0]
 [  1   5   0   0   1   0  99   0   0   0]
 [  0   1   1   0   1   0   0  89   0   5]
 [  0   3   0   0   1   3   0   1  77   2]
 [  0   2   0   0   1   0   0  13   0  96]]
              precision    recall  f1-score   support

           0       0.99      0.97      0.98        97
           1       0.80      0.99      0.89        95
           2       0.99      0.93      0.96       111
           3       0.93      0.96      0.95       103
           4       0.94      0.85      0.90        95
           5       0.94      0.92      0.93        97
           6       0.98      0.93      0.96       106
           7       0.82      0.92      0.86        97
           8       0.96      0.89      0.92        87
           9       0.90      0.86      0.88       112

    accuracy                           0.92      1000
   macro avg       0.93      0.92      0.92      1000
weighted avg       0.93      0.92      0.92      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_10x30.txt 3 EU 
Loading data...
Spliting data...
Using n_neighbors=3
Using metric=euclidean
Fitting knn
Predicting...
Accuracy:  0.908
[[ 95   0   0   0   0   1   1   0   0   0]
 [  0  94   0   0   0   0   0   0   0   1]
 [  0   6 100   0   1   0   1   2   1   0]
 [  0   1   1  97   0   1   0   1   2   0]
 [  0  11   1   0  82   0   0   0   0   1]
 [  1   1   0   6   0  88   1   0   0   0]
 [  1   7   0   0   1   0  97   0   0   0]
 [  1   7   1   0   0   0   0  83   0   5]
 [  1   3   0   3   0   0   0   3  77   0]
 [  0   2   0   0   4   0   0  10   1  95]]
              precision    recall  f1-score   support

           0       0.96      0.98      0.97        97
           1       0.71      0.99      0.83        95
           2       0.97      0.90      0.93       111
           3       0.92      0.94      0.93       103
           4       0.93      0.86      0.90        95
           5       0.98      0.91      0.94        97
           6       0.97      0.92      0.94       106
           7       0.84      0.86      0.85        97
           8       0.95      0.89      0.92        87
           9       0.93      0.85      0.89       112

    accuracy                           0.91      1000
   macro avg       0.92      0.91      0.91      1000
weighted avg       0.92      0.91      0.91      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_10x30.txt 3 MA 
Loading data...
Spliting data...
Using n_neighbors=3
Using metric=manhattan
Fitting knn
Predicting...
Accuracy:  0.908
[[ 95   0   0   0   0   1   1   0   0   0]
 [  0  94   0   0   0   0   0   0   0   1]
 [  0   6 100   0   1   0   1   2   1   0]
 [  0   1   1  97   0   1   0   1   2   0]
 [  0  11   1   0  82   0   0   0   0   1]
 [  1   1   0   6   0  88   1   0   0   0]
 [  1   7   0   0   1   0  97   0   0   0]
 [  1   7   1   0   0   0   0  83   0   5]
 [  1   3   0   3   0   0   0   3  77   0]
 [  0   2   0   0   4   0   0  10   1  95]]
              precision    recall  f1-score   support

           0       0.96      0.98      0.97        97
           1       0.71      0.99      0.83        95
           2       0.97      0.90      0.93       111
           3       0.92      0.94      0.93       103
           4       0.93      0.86      0.90        95
           5       0.98      0.91      0.94        97
           6       0.97      0.92      0.94       106
           7       0.84      0.86      0.85        97
           8       0.95      0.89      0.92        87
           9       0.93      0.85      0.89       112

    accuracy                           0.91      1000
   macro avg       0.92      0.91      0.91      1000
weighted avg       0.92      0.91      0.91      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_10x30.txt 3 MI 
Loading data...
Spliting data...
Using n_neighbors=3
Using metric=minkowski
Fitting knn
Predicting...
Accuracy:  0.908
[[ 95   0   0   0   0   1   1   0   0   0]
 [  0  94   0   0   0   0   0   0   0   1]
 [  0   6 100   0   1   0   1   2   1   0]
 [  0   1   1  97   0   1   0   1   2   0]
 [  0  11   1   0  82   0   0   0   0   1]
 [  1   1   0   6   0  88   1   0   0   0]
 [  1   7   0   0   1   0  97   0   0   0]
 [  1   7   1   0   0   0   0  83   0   5]
 [  1   3   0   3   0   0   0   3  77   0]
 [  0   2   0   0   4   0   0  10   1  95]]
              precision    recall  f1-score   support

           0       0.96      0.98      0.97        97
           1       0.71      0.99      0.83        95
           2       0.97      0.90      0.93       111
           3       0.92      0.94      0.93       103
           4       0.93      0.86      0.90        95
           5       0.98      0.91      0.94        97
           6       0.97      0.92      0.94       106
           7       0.84      0.86      0.85        97
           8       0.95      0.89      0.92        87
           9       0.93      0.85      0.89       112

    accuracy                           0.91      1000
   macro avg       0.92      0.91      0.91      1000
weighted avg       0.92      0.91      0.91      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_10x30.txt 5 EU 
Loading data...
Spliting data...
Using n_neighbors=5
Using metric=euclidean
Fitting knn
Predicting...
Accuracy:  0.902
[[ 96   0   0   0   0   1   0   0   0   0]
 [  0  94   0   1   0   0   0   0   0   0]
 [  0   6 100   0   1   0   1   3   0   0]
 [  0   1   1  98   0   0   0   2   1   0]
 [  0  11   1   0  81   0   0   0   0   2]
 [  2   1   0   6   0  87   1   0   0   0]
 [  1   7   0   0   0   0  98   0   0   0]
 [  0   7   0   0   1   0   0  84   0   5]
 [  0   5   0   3   0   2   0   3  74   0]
 [  0   2   0   0   7   0   0  12   1  90]]
              precision    recall  f1-score   support

           0       0.97      0.99      0.98        97
           1       0.70      0.99      0.82        95
           2       0.98      0.90      0.94       111
           3       0.91      0.95      0.93       103
           4       0.90      0.85      0.88        95
           5       0.97      0.90      0.93        97
           6       0.98      0.92      0.95       106
           7       0.81      0.87      0.84        97
           8       0.97      0.85      0.91        87
           9       0.93      0.80      0.86       112

    accuracy                           0.90      1000
   macro avg       0.91      0.90      0.90      1000
weighted avg       0.91      0.90      0.90      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_10x30.txt 5 MA 
Loading data...
Spliting data...
Using n_neighbors=5
Using metric=manhattan
Fitting knn
Predicting...
Accuracy:  0.902
[[ 96   0   0   0   0   1   0   0   0   0]
 [  0  94   0   1   0   0   0   0   0   0]
 [  0   6 100   0   1   0   1   3   0   0]
 [  0   1   1  98   0   0   0   2   1   0]
 [  0  11   1   0  81   0   0   0   0   2]
 [  2   1   0   6   0  87   1   0   0   0]
 [  1   7   0   0   0   0  98   0   0   0]
 [  0   7   0   0   1   0   0  84   0   5]
 [  0   5   0   3   0   2   0   3  74   0]
 [  0   2   0   0   7   0   0  12   1  90]]
              precision    recall  f1-score   support

           0       0.97      0.99      0.98        97
           1       0.70      0.99      0.82        95
           2       0.98      0.90      0.94       111
           3       0.91      0.95      0.93       103
           4       0.90      0.85      0.88        95
           5       0.97      0.90      0.93        97
           6       0.98      0.92      0.95       106
           7       0.81      0.87      0.84        97
           8       0.97      0.85      0.91        87
           9       0.93      0.80      0.86       112

    accuracy                           0.90      1000
   macro avg       0.91      0.90      0.90      1000
weighted avg       0.91      0.90      0.90      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_10x30.txt 5 MI 
Loading data...
Spliting data...
Using n_neighbors=5
Using metric=minkowski
Fitting knn
Predicting...
Accuracy:  0.902
[[ 96   0   0   0   0   1   0   0   0   0]
 [  0  94   0   1   0   0   0   0   0   0]
 [  0   6 100   0   1   0   1   3   0   0]
 [  0   1   1  98   0   0   0   2   1   0]
 [  0  11   1   0  81   0   0   0   0   2]
 [  2   1   0   6   0  87   1   0   0   0]
 [  1   7   0   0   0   0  98   0   0   0]
 [  0   7   0   0   1   0   0  84   0   5]
 [  0   5   0   3   0   2   0   3  74   0]
 [  0   2   0   0   7   0   0  12   1  90]]
              precision    recall  f1-score   support

           0       0.97      0.99      0.98        97
           1       0.70      0.99      0.82        95
           2       0.98      0.90      0.94       111
           3       0.91      0.95      0.93       103
           4       0.90      0.85      0.88        95
           5       0.97      0.90      0.93        97
           6       0.98      0.92      0.95       106
           7       0.81      0.87      0.84        97
           8       0.97      0.85      0.91        87
           9       0.93      0.80      0.86       112

    accuracy                           0.90      1000
   macro avg       0.91      0.90      0.90      1000
weighted avg       0.91      0.90      0.90      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_12x15.txt 1 EU 
Loading data...
Spliting data...
Using n_neighbors=1
Using metric=euclidean
Fitting knn
Predicting...
Accuracy:  0.909
[[ 93   1   0   0   0   1   2   0   0   0]
 [  0  93   0   0   0   1   0   0   0   1]
 [  0   3 100   2   0   0   0   2   2   2]
 [  1   1   1  97   0   1   0   1   1   0]
 [  0  10   0   0  80   1   1   0   0   3]
 [  1   1   0   8   0  86   1   0   0   0]
 [  1   4   0   0   0   0 101   0   0   0]
 [  0   1   1   0   1   0   0  90   0   4]
 [  0   5   0   3   0   2   0   0  76   1]
 [  0   1   0   0   4   0   0  14   0  93]]
              precision    recall  f1-score   support

           0       0.97      0.96      0.96        97
           1       0.78      0.98      0.87        95
           2       0.98      0.90      0.94       111
           3       0.88      0.94      0.91       103
           4       0.94      0.84      0.89        95
           5       0.93      0.89      0.91        97
           6       0.96      0.95      0.96       106
           7       0.84      0.93      0.88        97
           8       0.96      0.87      0.92        87
           9       0.89      0.83      0.86       112

    accuracy                           0.91      1000
   macro avg       0.91      0.91      0.91      1000
weighted avg       0.91      0.91      0.91      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_12x15.txt 1 MA 
Loading data...
Spliting data...
Using n_neighbors=1
Using metric=manhattan
Fitting knn
Predicting...
Accuracy:  0.909
[[ 93   1   0   0   0   1   2   0   0   0]
 [  0  93   0   0   0   1   0   0   0   1]
 [  0   3 100   2   0   0   0   2   2   2]
 [  1   1   1  97   0   1   0   1   1   0]
 [  0  10   0   0  80   1   1   0   0   3]
 [  1   1   0   8   0  86   1   0   0   0]
 [  1   4   0   0   0   0 101   0   0   0]
 [  0   1   1   0   1   0   0  90   0   4]
 [  0   5   0   3   0   2   0   0  76   1]
 [  0   1   0   0   4   0   0  14   0  93]]
              precision    recall  f1-score   support

           0       0.97      0.96      0.96        97
           1       0.78      0.98      0.87        95
           2       0.98      0.90      0.94       111
           3       0.88      0.94      0.91       103
           4       0.94      0.84      0.89        95
           5       0.93      0.89      0.91        97
           6       0.96      0.95      0.96       106
           7       0.84      0.93      0.88        97
           8       0.96      0.87      0.92        87
           9       0.89      0.83      0.86       112

    accuracy                           0.91      1000
   macro avg       0.91      0.91      0.91      1000
weighted avg       0.91      0.91      0.91      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_12x15.txt 1 MI 
Loading data...
Spliting data...
Using n_neighbors=1
Using metric=minkowski
Fitting knn
Predicting...
Accuracy:  0.909
[[ 93   1   0   0   0   1   2   0   0   0]
 [  0  93   0   0   0   1   0   0   0   1]
 [  0   3 100   2   0   0   0   2   2   2]
 [  1   1   1  97   0   1   0   1   1   0]
 [  0  10   0   0  80   1   1   0   0   3]
 [  1   1   0   8   0  86   1   0   0   0]
 [  1   4   0   0   0   0 101   0   0   0]
 [  0   1   1   0   1   0   0  90   0   4]
 [  0   5   0   3   0   2   0   0  76   1]
 [  0   1   0   0   4   0   0  14   0  93]]
              precision    recall  f1-score   support

           0       0.97      0.96      0.96        97
           1       0.78      0.98      0.87        95
           2       0.98      0.90      0.94       111
           3       0.88      0.94      0.91       103
           4       0.94      0.84      0.89        95
           5       0.93      0.89      0.91        97
           6       0.96      0.95      0.96       106
           7       0.84      0.93      0.88        97
           8       0.96      0.87      0.92        87
           9       0.89      0.83      0.86       112

    accuracy                           0.91      1000
   macro avg       0.91      0.91      0.91      1000
weighted avg       0.91      0.91      0.91      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_12x15.txt 3 EU 
Loading data...
Spliting data...
Using n_neighbors=3
Using metric=euclidean
Fitting knn
Predicting...
Accuracy:  0.907
[[ 95   1   0   0   0   1   0   0   0   0]
 [  0  94   0   1   0   0   0   0   0   0]
 [  0   3 100   1   0   0   1   3   1   2]
 [  0   1   2  97   0   1   0   1   1   0]
 [  0  10   1   0  81   0   1   0   0   2]
 [  1   1   0   9   0  85   1   0   0   0]
 [  2   3   0   0   0   0 101   0   0   0]
 [  1   4   1   0   0   0   0  85   0   6]
 [  0   3   0   4   0   1   0   2  76   1]
 [  0   4   0   0   6   0   0   9   0  93]]
              precision    recall  f1-score   support

           0       0.96      0.98      0.97        97
           1       0.76      0.99      0.86        95
           2       0.96      0.90      0.93       111
           3       0.87      0.94      0.90       103
           4       0.93      0.85      0.89        95
           5       0.97      0.88      0.92        97
           6       0.97      0.95      0.96       106
           7       0.85      0.88      0.86        97
           8       0.97      0.87      0.92        87
           9       0.89      0.83      0.86       112

    accuracy                           0.91      1000
   macro avg       0.91      0.91      0.91      1000
weighted avg       0.91      0.91      0.91      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_12x15.txt 3 MA 
Loading data...
Spliting data...
Using n_neighbors=3
Using metric=manhattan
Fitting knn
Predicting...
Accuracy:  0.907
[[ 95   1   0   0   0   1   0   0   0   0]
 [  0  94   0   1   0   0   0   0   0   0]
 [  0   3 100   1   0   0   1   3   1   2]
 [  0   1   2  97   0   1   0   1   1   0]
 [  0  10   1   0  81   0   1   0   0   2]
 [  1   1   0   9   0  85   1   0   0   0]
 [  2   3   0   0   0   0 101   0   0   0]
 [  1   4   1   0   0   0   0  85   0   6]
 [  0   3   0   4   0   1   0   2  76   1]
 [  0   4   0   0   6   0   0   9   0  93]]
              precision    recall  f1-score   support

           0       0.96      0.98      0.97        97
           1       0.76      0.99      0.86        95
           2       0.96      0.90      0.93       111
           3       0.87      0.94      0.90       103
           4       0.93      0.85      0.89        95
           5       0.97      0.88      0.92        97
           6       0.97      0.95      0.96       106
           7       0.85      0.88      0.86        97
           8       0.97      0.87      0.92        87
           9       0.89      0.83      0.86       112

    accuracy                           0.91      1000
   macro avg       0.91      0.91      0.91      1000
weighted avg       0.91      0.91      0.91      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_12x15.txt 3 MI 
Loading data...
Spliting data...
Using n_neighbors=3
Using metric=minkowski
Fitting knn
Predicting...
Accuracy:  0.907
[[ 95   1   0   0   0   1   0   0   0   0]
 [  0  94   0   1   0   0   0   0   0   0]
 [  0   3 100   1   0   0   1   3   1   2]
 [  0   1   2  97   0   1   0   1   1   0]
 [  0  10   1   0  81   0   1   0   0   2]
 [  1   1   0   9   0  85   1   0   0   0]
 [  2   3   0   0   0   0 101   0   0   0]
 [  1   4   1   0   0   0   0  85   0   6]
 [  0   3   0   4   0   1   0   2  76   1]
 [  0   4   0   0   6   0   0   9   0  93]]
              precision    recall  f1-score   support

           0       0.96      0.98      0.97        97
           1       0.76      0.99      0.86        95
           2       0.96      0.90      0.93       111
           3       0.87      0.94      0.90       103
           4       0.93      0.85      0.89        95
           5       0.97      0.88      0.92        97
           6       0.97      0.95      0.96       106
           7       0.85      0.88      0.86        97
           8       0.97      0.87      0.92        87
           9       0.89      0.83      0.86       112

    accuracy                           0.91      1000
   macro avg       0.91      0.91      0.91      1000
weighted avg       0.91      0.91      0.91      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_12x15.txt 5 EU 
Loading data...
Spliting data...
Using n_neighbors=5
Using metric=euclidean
Fitting knn
Predicting...
Accuracy:  0.892
[[95  1  0  0  0  1  0  0  0  0]
 [ 0 94  0  1  0  0  0  0  0  0]
 [ 0 10 92  2  1  0  1  4  0  1]
 [ 0  1  1 98  0  1  0  1  1  0]
 [ 0 10  1  0 82  0  0  0  0  2]
 [ 2  1  0  8  0 85  1  0  0  0]
 [ 2  5  0  0  0  0 99  0  0  0]
 [ 0  8  0  0  1  0  0 82  0  6]
 [ 0  7  0  6  0  1  0  1 72  0]
 [ 0  3  0  0  4  0  0 11  1 93]]
              precision    recall  f1-score   support

           0       0.96      0.98      0.97        97
           1       0.67      0.99      0.80        95
           2       0.98      0.83      0.90       111
           3       0.85      0.95      0.90       103
           4       0.93      0.86      0.90        95
           5       0.97      0.88      0.92        97
           6       0.98      0.93      0.96       106
           7       0.83      0.85      0.84        97
           8       0.97      0.83      0.89        87
           9       0.91      0.83      0.87       112

    accuracy                           0.89      1000
   macro avg       0.91      0.89      0.89      1000
weighted avg       0.91      0.89      0.89      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_12x15.txt 5 MA 
Loading data...
Spliting data...
Using n_neighbors=5
Using metric=manhattan
Fitting knn
Predicting...
Accuracy:  0.892
[[95  1  0  0  0  1  0  0  0  0]
 [ 0 94  0  1  0  0  0  0  0  0]
 [ 0 10 92  2  1  0  1  4  0  1]
 [ 0  1  1 98  0  1  0  1  1  0]
 [ 0 10  1  0 82  0  0  0  0  2]
 [ 2  1  0  8  0 85  1  0  0  0]
 [ 2  5  0  0  0  0 99  0  0  0]
 [ 0  8  0  0  1  0  0 82  0  6]
 [ 0  7  0  6  0  1  0  1 72  0]
 [ 0  3  0  0  4  0  0 11  1 93]]
              precision    recall  f1-score   support

           0       0.96      0.98      0.97        97
           1       0.67      0.99      0.80        95
           2       0.98      0.83      0.90       111
           3       0.85      0.95      0.90       103
           4       0.93      0.86      0.90        95
           5       0.97      0.88      0.92        97
           6       0.98      0.93      0.96       106
           7       0.83      0.85      0.84        97
           8       0.97      0.83      0.89        87
           9       0.91      0.83      0.87       112

    accuracy                           0.89      1000
   macro avg       0.91      0.89      0.89      1000
weighted avg       0.91      0.89      0.89      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_12x15.txt 5 MI 
Loading data...
Spliting data...
Using n_neighbors=5
Using metric=minkowski
Fitting knn
Predicting...
Accuracy:  0.892
[[95  1  0  0  0  1  0  0  0  0]
 [ 0 94  0  1  0  0  0  0  0  0]
 [ 0 10 92  2  1  0  1  4  0  1]
 [ 0  1  1 98  0  1  0  1  1  0]
 [ 0 10  1  0 82  0  0  0  0  2]
 [ 2  1  0  8  0 85  1  0  0  0]
 [ 2  5  0  0  0  0 99  0  0  0]
 [ 0  8  0  0  1  0  0 82  0  6]
 [ 0  7  0  6  0  1  0  1 72  0]
 [ 0  3  0  0  4  0  0 11  1 93]]
              precision    recall  f1-score   support

           0       0.96      0.98      0.97        97
           1       0.67      0.99      0.80        95
           2       0.98      0.83      0.90       111
           3       0.85      0.95      0.90       103
           4       0.93      0.86      0.90        95
           5       0.97      0.88      0.92        97
           6       0.98      0.93      0.96       106
           7       0.83      0.85      0.84        97
           8       0.97      0.83      0.89        87
           9       0.91      0.83      0.87       112

    accuracy                           0.89      1000
   macro avg       0.91      0.89      0.89      1000
weighted avg       0.91      0.89      0.89      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_20x10.txt 1 EU 
Loading data...
Spliting data...
Using n_neighbors=1
Using metric=euclidean
Fitting knn
Predicting...
Accuracy:  0.908
[[ 95   1   0   0   0   1   0   0   0   0]
 [  0  93   0   0   0   1   0   0   0   1]
 [  2   2 100   1   0   0   1   4   1   0]
 [  1   2   2  92   0   1   0   1   4   0]
 [  0   9   0   0  82   0   1   1   0   2]
 [  0   0   0   6   0  88   0   0   3   0]
 [  0   6   0   0   0   0 100   0   0   0]
 [  0   2   1   0   1   0   0  89   0   4]
 [  1   4   0   2   1   2   0   2  74   1]
 [  0   0   0   0   5   0   0  12   0  95]]
              precision    recall  f1-score   support

           0       0.96      0.98      0.97        97
           1       0.78      0.98      0.87        95
           2       0.97      0.90      0.93       111
           3       0.91      0.89      0.90       103
           4       0.92      0.86      0.89        95
           5       0.95      0.91      0.93        97
           6       0.98      0.94      0.96       106
           7       0.82      0.92      0.86        97
           8       0.90      0.85      0.88        87
           9       0.92      0.85      0.88       112

    accuracy                           0.91      1000
   macro avg       0.91      0.91      0.91      1000
weighted avg       0.91      0.91      0.91      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_20x10.txt 1 MA 
Loading data...
Spliting data...
Using n_neighbors=1
Using metric=manhattan
Fitting knn
Predicting...
Accuracy:  0.908
[[ 95   1   0   0   0   1   0   0   0   0]
 [  0  93   0   0   0   1   0   0   0   1]
 [  2   2 100   1   0   0   1   4   1   0]
 [  1   2   2  92   0   1   0   1   4   0]
 [  0   9   0   0  82   0   1   1   0   2]
 [  0   0   0   6   0  88   0   0   3   0]
 [  0   6   0   0   0   0 100   0   0   0]
 [  0   2   1   0   1   0   0  89   0   4]
 [  1   4   0   2   1   2   0   2  74   1]
 [  0   0   0   0   5   0   0  12   0  95]]
              precision    recall  f1-score   support

           0       0.96      0.98      0.97        97
           1       0.78      0.98      0.87        95
           2       0.97      0.90      0.93       111
           3       0.91      0.89      0.90       103
           4       0.92      0.86      0.89        95
           5       0.95      0.91      0.93        97
           6       0.98      0.94      0.96       106
           7       0.82      0.92      0.86        97
           8       0.90      0.85      0.88        87
           9       0.92      0.85      0.88       112

    accuracy                           0.91      1000
   macro avg       0.91      0.91      0.91      1000
weighted avg       0.91      0.91      0.91      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_20x10.txt 1 MI 
Loading data...
Spliting data...
Using n_neighbors=1
Using metric=minkowski
Fitting knn
Predicting...
Accuracy:  0.908
[[ 95   1   0   0   0   1   0   0   0   0]
 [  0  93   0   0   0   1   0   0   0   1]
 [  2   2 100   1   0   0   1   4   1   0]
 [  1   2   2  92   0   1   0   1   4   0]
 [  0   9   0   0  82   0   1   1   0   2]
 [  0   0   0   6   0  88   0   0   3   0]
 [  0   6   0   0   0   0 100   0   0   0]
 [  0   2   1   0   1   0   0  89   0   4]
 [  1   4   0   2   1   2   0   2  74   1]
 [  0   0   0   0   5   0   0  12   0  95]]
              precision    recall  f1-score   support

           0       0.96      0.98      0.97        97
           1       0.78      0.98      0.87        95
           2       0.97      0.90      0.93       111
           3       0.91      0.89      0.90       103
           4       0.92      0.86      0.89        95
           5       0.95      0.91      0.93        97
           6       0.98      0.94      0.96       106
           7       0.82      0.92      0.86        97
           8       0.90      0.85      0.88        87
           9       0.92      0.85      0.88       112

    accuracy                           0.91      1000
   macro avg       0.91      0.91      0.91      1000
weighted avg       0.91      0.91      0.91      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_20x10.txt 3 EU 
Loading data...
Spliting data...
Using n_neighbors=3
Using metric=euclidean
Fitting knn
Predicting...
Accuracy:  0.905
[[ 95   1   0   0   0   1   0   0   0   0]
 [  0  94   0   1   0   0   0   0   0   0]
 [  2   7  98   0   1   0   0   2   1   0]
 [  0   1   1  93   1   3   0   1   3   0]
 [  0  10   1   0  81   0   0   0   0   3]
 [  1   1   0   5   0  89   0   0   1   0]
 [  0   5   0   0   0   0 101   0   0   0]
 [  1   7   0   0   0   0   0  84   0   5]
 [  1   3   0   3   1   1   0   2  75   1]
 [  0   1   1   0   4   0   0  11   0  95]]
              precision    recall  f1-score   support

           0       0.95      0.98      0.96        97
           1       0.72      0.99      0.84        95
           2       0.97      0.88      0.92       111
           3       0.91      0.90      0.91       103
           4       0.92      0.85      0.89        95
           5       0.95      0.92      0.93        97
           6       1.00      0.95      0.98       106
           7       0.84      0.87      0.85        97
           8       0.94      0.86      0.90        87
           9       0.91      0.85      0.88       112

    accuracy                           0.91      1000
   macro avg       0.91      0.91      0.91      1000
weighted avg       0.91      0.91      0.91      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_20x10.txt 3 MA 
Loading data...
Spliting data...
Using n_neighbors=3
Using metric=manhattan
Fitting knn
Predicting...
Accuracy:  0.905
[[ 95   1   0   0   0   1   0   0   0   0]
 [  0  94   0   1   0   0   0   0   0   0]
 [  2   7  98   0   1   0   0   2   1   0]
 [  0   1   1  93   1   3   0   1   3   0]
 [  0  10   1   0  81   0   0   0   0   3]
 [  1   1   0   5   0  89   0   0   1   0]
 [  0   5   0   0   0   0 101   0   0   0]
 [  1   7   0   0   0   0   0  84   0   5]
 [  1   3   0   3   1   1   0   2  75   1]
 [  0   1   1   0   4   0   0  11   0  95]]
              precision    recall  f1-score   support

           0       0.95      0.98      0.96        97
           1       0.72      0.99      0.84        95
           2       0.97      0.88      0.92       111
           3       0.91      0.90      0.91       103
           4       0.92      0.85      0.89        95
           5       0.95      0.92      0.93        97
           6       1.00      0.95      0.98       106
           7       0.84      0.87      0.85        97
           8       0.94      0.86      0.90        87
           9       0.91      0.85      0.88       112

    accuracy                           0.91      1000
   macro avg       0.91      0.91      0.91      1000
weighted avg       0.91      0.91      0.91      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_20x10.txt 3 MI 
Loading data...
Spliting data...
Using n_neighbors=3
Using metric=minkowski
Fitting knn
Predicting...
Accuracy:  0.905
[[ 95   1   0   0   0   1   0   0   0   0]
 [  0  94   0   1   0   0   0   0   0   0]
 [  2   7  98   0   1   0   0   2   1   0]
 [  0   1   1  93   1   3   0   1   3   0]
 [  0  10   1   0  81   0   0   0   0   3]
 [  1   1   0   5   0  89   0   0   1   0]
 [  0   5   0   0   0   0 101   0   0   0]
 [  1   7   0   0   0   0   0  84   0   5]
 [  1   3   0   3   1   1   0   2  75   1]
 [  0   1   1   0   4   0   0  11   0  95]]
              precision    recall  f1-score   support

           0       0.95      0.98      0.96        97
           1       0.72      0.99      0.84        95
           2       0.97      0.88      0.92       111
           3       0.91      0.90      0.91       103
           4       0.92      0.85      0.89        95
           5       0.95      0.92      0.93        97
           6       1.00      0.95      0.98       106
           7       0.84      0.87      0.85        97
           8       0.94      0.86      0.90        87
           9       0.91      0.85      0.88       112

    accuracy                           0.91      1000
   macro avg       0.91      0.91      0.91      1000
weighted avg       0.91      0.91      0.91      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_20x10.txt 5 EU 
Loading data...
Spliting data...
Using n_neighbors=5
Using metric=euclidean
Fitting knn
Predicting...
Accuracy:  0.901
[[ 95   1   0   0   0   1   0   0   0   0]
 [  0  94   0   1   0   0   0   0   0   0]
 [  2   9  94   1   0   0   0   4   1   0]
 [  0   1   1  97   0   0   0   1   3   0]
 [  0   9   0   0  83   0   1   0   0   2]
 [  0   1   0   8   0  87   1   0   0   0]
 [  1   4   0   0   0   0 101   0   0   0]
 [  0   9   0   0   1   0   0  83   0   4]
 [  0   4   0   2   0   1   0   3  74   3]
 [  0   3   0   0   4   0   0  12   0  93]]
              precision    recall  f1-score   support

           0       0.97      0.98      0.97        97
           1       0.70      0.99      0.82        95
           2       0.99      0.85      0.91       111
           3       0.89      0.94      0.92       103
           4       0.94      0.87      0.91        95
           5       0.98      0.90      0.94        97
           6       0.98      0.95      0.97       106
           7       0.81      0.86      0.83        97
           8       0.95      0.85      0.90        87
           9       0.91      0.83      0.87       112

    accuracy                           0.90      1000
   macro avg       0.91      0.90      0.90      1000
weighted avg       0.91      0.90      0.90      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_20x10.txt 5 MA 
Loading data...
Spliting data...
Using n_neighbors=5
Using metric=manhattan
Fitting knn
Predicting...
Accuracy:  0.901
[[ 95   1   0   0   0   1   0   0   0   0]
 [  0  94   0   1   0   0   0   0   0   0]
 [  2   9  94   1   0   0   0   4   1   0]
 [  0   1   1  97   0   0   0   1   3   0]
 [  0   9   0   0  83   0   1   0   0   2]
 [  0   1   0   8   0  87   1   0   0   0]
 [  1   4   0   0   0   0 101   0   0   0]
 [  0   9   0   0   1   0   0  83   0   4]
 [  0   4   0   2   0   1   0   3  74   3]
 [  0   3   0   0   4   0   0  12   0  93]]
              precision    recall  f1-score   support

           0       0.97      0.98      0.97        97
           1       0.70      0.99      0.82        95
           2       0.99      0.85      0.91       111
           3       0.89      0.94      0.92       103
           4       0.94      0.87      0.91        95
           5       0.98      0.90      0.94        97
           6       0.98      0.95      0.97       106
           7       0.81      0.86      0.83        97
           8       0.95      0.85      0.90        87
           9       0.91      0.83      0.87       112

    accuracy                           0.90      1000
   macro avg       0.91      0.90      0.90      1000
weighted avg       0.91      0.90      0.90      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_20x10.txt 5 MI 
Loading data...
Spliting data...
Using n_neighbors=5
Using metric=minkowski
Fitting knn
Predicting...
Accuracy:  0.901
[[ 95   1   0   0   0   1   0   0   0   0]
 [  0  94   0   1   0   0   0   0   0   0]
 [  2   9  94   1   0   0   0   4   1   0]
 [  0   1   1  97   0   0   0   1   3   0]
 [  0   9   0   0  83   0   1   0   0   2]
 [  0   1   0   8   0  87   1   0   0   0]
 [  1   4   0   0   0   0 101   0   0   0]
 [  0   9   0   0   1   0   0  83   0   4]
 [  0   4   0   2   0   1   0   3  74   3]
 [  0   3   0   0   4   0   0  12   0  93]]
              precision    recall  f1-score   support

           0       0.97      0.98      0.97        97
           1       0.70      0.99      0.82        95
           2       0.99      0.85      0.91       111
           3       0.89      0.94      0.92       103
           4       0.94      0.87      0.91        95
           5       0.98      0.90      0.94        97
           6       0.98      0.95      0.97       106
           7       0.81      0.86      0.83        97
           8       0.95      0.85      0.90        87
           9       0.91      0.83      0.87       112

    accuracy                           0.90      1000
   macro avg       0.91      0.90      0.90      1000
weighted avg       0.91      0.90      0.90      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_20x25.txt 1 EU 
Loading data...
Spliting data...
Using n_neighbors=1
Using metric=euclidean
Fitting knn
Predicting...
Accuracy:  0.925
[[ 93   1   0   0   0   2   1   0   0   0]
 [  0  94   0   0   0   0   0   1   0   0]
 [  0   2 101   2   0   0   0   4   1   1]
 [  1   1   0  98   0   1   0   1   1   0]
 [  0   8   0   0  84   0   1   0   0   2]
 [  2   0   0   5   0  89   1   0   0   0]
 [  2   5   0   0   1   0  98   0   0   0]
 [  0   2   1   0   1   0   0  89   0   4]
 [  0   2   0   3   1   1   0   0  80   0]
 [  0   0   0   0   2   0   0  11   0  99]]
              precision    recall  f1-score   support

           0       0.95      0.96      0.95        97
           1       0.82      0.99      0.90        95
           2       0.99      0.91      0.95       111
           3       0.91      0.95      0.93       103
           4       0.94      0.88      0.91        95
           5       0.96      0.92      0.94        97
           6       0.97      0.92      0.95       106
           7       0.84      0.92      0.88        97
           8       0.98      0.92      0.95        87
           9       0.93      0.88      0.91       112

    accuracy                           0.93      1000
   macro avg       0.93      0.93      0.93      1000
weighted avg       0.93      0.93      0.93      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_20x25.txt 1 MA 
Loading data...
Spliting data...
Using n_neighbors=1
Using metric=manhattan
Fitting knn
Predicting...
Accuracy:  0.925
[[ 93   1   0   0   0   2   1   0   0   0]
 [  0  94   0   0   0   0   0   1   0   0]
 [  0   2 101   2   0   0   0   4   1   1]
 [  1   1   0  98   0   1   0   1   1   0]
 [  0   8   0   0  84   0   1   0   0   2]
 [  2   0   0   5   0  89   1   0   0   0]
 [  2   5   0   0   1   0  98   0   0   0]
 [  0   2   1   0   1   0   0  89   0   4]
 [  0   2   0   3   1   1   0   0  80   0]
 [  0   0   0   0   2   0   0  11   0  99]]
              precision    recall  f1-score   support

           0       0.95      0.96      0.95        97
           1       0.82      0.99      0.90        95
           2       0.99      0.91      0.95       111
           3       0.91      0.95      0.93       103
           4       0.94      0.88      0.91        95
           5       0.96      0.92      0.94        97
           6       0.97      0.92      0.95       106
           7       0.84      0.92      0.88        97
           8       0.98      0.92      0.95        87
           9       0.93      0.88      0.91       112

    accuracy                           0.93      1000
   macro avg       0.93      0.93      0.93      1000
weighted avg       0.93      0.93      0.93      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_20x25.txt 1 MI 
Loading data...
Spliting data...
Using n_neighbors=1
Using metric=minkowski
Fitting knn
Predicting...
Accuracy:  0.925
[[ 93   1   0   0   0   2   1   0   0   0]
 [  0  94   0   0   0   0   0   1   0   0]
 [  0   2 101   2   0   0   0   4   1   1]
 [  1   1   0  98   0   1   0   1   1   0]
 [  0   8   0   0  84   0   1   0   0   2]
 [  2   0   0   5   0  89   1   0   0   0]
 [  2   5   0   0   1   0  98   0   0   0]
 [  0   2   1   0   1   0   0  89   0   4]
 [  0   2   0   3   1   1   0   0  80   0]
 [  0   0   0   0   2   0   0  11   0  99]]
              precision    recall  f1-score   support

           0       0.95      0.96      0.95        97
           1       0.82      0.99      0.90        95
           2       0.99      0.91      0.95       111
           3       0.91      0.95      0.93       103
           4       0.94      0.88      0.91        95
           5       0.96      0.92      0.94        97
           6       0.97      0.92      0.95       106
           7       0.84      0.92      0.88        97
           8       0.98      0.92      0.95        87
           9       0.93      0.88      0.91       112

    accuracy                           0.93      1000
   macro avg       0.93      0.93      0.93      1000
weighted avg       0.93      0.93      0.93      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_20x25.txt 3 EU 
Loading data...
Spliting data...
Using n_neighbors=3
Using metric=euclidean
Fitting knn
Predicting...
Accuracy:  0.928
[[ 96   0   0   0   0   1   0   0   0   0]
 [  0  95   0   0   0   0   0   0   0   0]
 [  0   5 101   0   1   0   1   3   0   0]
 [  1   1   0 100   0   1   0   0   0   0]
 [  0   9   2   0  82   0   0   0   0   2]
 [  1   0   0   4   0  91   1   0   0   0]
 [  1   5   0   0   0   0 100   0   0   0]
 [  0   7   0   0   0   0   0  87   0   3]
 [  0   2   1   4   1   2   0   2  75   0]
 [  0   0   0   0   3   0   0   7   1 101]]
              precision    recall  f1-score   support

           0       0.97      0.99      0.98        97
           1       0.77      1.00      0.87        95
           2       0.97      0.91      0.94       111
           3       0.93      0.97      0.95       103
           4       0.94      0.86      0.90        95
           5       0.96      0.94      0.95        97
           6       0.98      0.94      0.96       106
           7       0.88      0.90      0.89        97
           8       0.99      0.86      0.92        87
           9       0.95      0.90      0.93       112

    accuracy                           0.93      1000
   macro avg       0.93      0.93      0.93      1000
weighted avg       0.93      0.93      0.93      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_20x25.txt 3 MA 
Loading data...
Spliting data...
Using n_neighbors=3
Using metric=manhattan
Fitting knn
Predicting...
Accuracy:  0.928
[[ 96   0   0   0   0   1   0   0   0   0]
 [  0  95   0   0   0   0   0   0   0   0]
 [  0   5 101   0   1   0   1   3   0   0]
 [  1   1   0 100   0   1   0   0   0   0]
 [  0   9   2   0  82   0   0   0   0   2]
 [  1   0   0   4   0  91   1   0   0   0]
 [  1   5   0   0   0   0 100   0   0   0]
 [  0   7   0   0   0   0   0  87   0   3]
 [  0   2   1   4   1   2   0   2  75   0]
 [  0   0   0   0   3   0   0   7   1 101]]
              precision    recall  f1-score   support

           0       0.97      0.99      0.98        97
           1       0.77      1.00      0.87        95
           2       0.97      0.91      0.94       111
           3       0.93      0.97      0.95       103
           4       0.94      0.86      0.90        95
           5       0.96      0.94      0.95        97
           6       0.98      0.94      0.96       106
           7       0.88      0.90      0.89        97
           8       0.99      0.86      0.92        87
           9       0.95      0.90      0.93       112

    accuracy                           0.93      1000
   macro avg       0.93      0.93      0.93      1000
weighted avg       0.93      0.93      0.93      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_20x25.txt 3 MI 
Loading data...
Spliting data...
Using n_neighbors=3
Using metric=minkowski
Fitting knn
Predicting...
Accuracy:  0.928
[[ 96   0   0   0   0   1   0   0   0   0]
 [  0  95   0   0   0   0   0   0   0   0]
 [  0   5 101   0   1   0   1   3   0   0]
 [  1   1   0 100   0   1   0   0   0   0]
 [  0   9   2   0  82   0   0   0   0   2]
 [  1   0   0   4   0  91   1   0   0   0]
 [  1   5   0   0   0   0 100   0   0   0]
 [  0   7   0   0   0   0   0  87   0   3]
 [  0   2   1   4   1   2   0   2  75   0]
 [  0   0   0   0   3   0   0   7   1 101]]
              precision    recall  f1-score   support

           0       0.97      0.99      0.98        97
           1       0.77      1.00      0.87        95
           2       0.97      0.91      0.94       111
           3       0.93      0.97      0.95       103
           4       0.94      0.86      0.90        95
           5       0.96      0.94      0.95        97
           6       0.98      0.94      0.96       106
           7       0.88      0.90      0.89        97
           8       0.99      0.86      0.92        87
           9       0.95      0.90      0.93       112

    accuracy                           0.93      1000
   macro avg       0.93      0.93      0.93      1000
weighted avg       0.93      0.93      0.93      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_20x25.txt 5 EU 
Loading data...
Spliting data...
Using n_neighbors=5
Using metric=euclidean
Fitting knn
Predicting...
Accuracy:  0.908
[[ 95   1   0   0   0   1   0   0   0   0]
 [  0  95   0   0   0   0   0   0   0   0]
 [  0   8  97   1   1   0   1   3   0   0]
 [  0   1   0  97   0   1   0   3   1   0]
 [  0  11   2   0  82   0   0   0   0   0]
 [  1   1   0   7   0  87   1   0   0   0]
 [  0   6   0   0   0   0 100   0   0   0]
 [  0   8   0   0   1   0   0  85   0   3]
 [  0   4   0   4   0   2   0   2  74   1]
 [  0   2   0   0   4   0   0  10   0  96]]
              precision    recall  f1-score   support

           0       0.99      0.98      0.98        97
           1       0.69      1.00      0.82        95
           2       0.98      0.87      0.92       111
           3       0.89      0.94      0.92       103
           4       0.93      0.86      0.90        95
           5       0.96      0.90      0.93        97
           6       0.98      0.94      0.96       106
           7       0.83      0.88      0.85        97
           8       0.99      0.85      0.91        87
           9       0.96      0.86      0.91       112

    accuracy                           0.91      1000
   macro avg       0.92      0.91      0.91      1000
weighted avg       0.92      0.91      0.91      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_20x25.txt 5 MA 
Loading data...
Spliting data...
Using n_neighbors=5
Using metric=manhattan
Fitting knn
Predicting...
Accuracy:  0.908
[[ 95   1   0   0   0   1   0   0   0   0]
 [  0  95   0   0   0   0   0   0   0   0]
 [  0   8  97   1   1   0   1   3   0   0]
 [  0   1   0  97   0   1   0   3   1   0]
 [  0  11   2   0  82   0   0   0   0   0]
 [  1   1   0   7   0  87   1   0   0   0]
 [  0   6   0   0   0   0 100   0   0   0]
 [  0   8   0   0   1   0   0  85   0   3]
 [  0   4   0   4   0   2   0   2  74   1]
 [  0   2   0   0   4   0   0  10   0  96]]
              precision    recall  f1-score   support

           0       0.99      0.98      0.98        97
           1       0.69      1.00      0.82        95
           2       0.98      0.87      0.92       111
           3       0.89      0.94      0.92       103
           4       0.93      0.86      0.90        95
           5       0.96      0.90      0.93        97
           6       0.98      0.94      0.96       106
           7       0.83      0.88      0.85        97
           8       0.99      0.85      0.91        87
           9       0.96      0.86      0.91       112

    accuracy                           0.91      1000
   macro avg       0.92      0.91      0.91      1000
weighted avg       0.92      0.91      0.91      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_20x25.txt 5 MI 
Loading data...
Spliting data...
Using n_neighbors=5
Using metric=minkowski
Fitting knn
Predicting...
Accuracy:  0.908
[[ 95   1   0   0   0   1   0   0   0   0]
 [  0  95   0   0   0   0   0   0   0   0]
 [  0   8  97   1   1   0   1   3   0   0]
 [  0   1   0  97   0   1   0   3   1   0]
 [  0  11   2   0  82   0   0   0   0   0]
 [  1   1   0   7   0  87   1   0   0   0]
 [  0   6   0   0   0   0 100   0   0   0]
 [  0   8   0   0   1   0   0  85   0   3]
 [  0   4   0   4   0   2   0   2  74   1]
 [  0   2   0   0   4   0   0  10   0  96]]
              precision    recall  f1-score   support

           0       0.99      0.98      0.98        97
           1       0.69      1.00      0.82        95
           2       0.98      0.87      0.92       111
           3       0.89      0.94      0.92       103
           4       0.93      0.86      0.90        95
           5       0.96      0.90      0.93        97
           6       0.98      0.94      0.96       106
           7       0.83      0.88      0.85        97
           8       0.99      0.85      0.91        87
           9       0.96      0.86      0.91       112

    accuracy                           0.91      1000
   macro avg       0.92      0.91      0.91      1000
weighted avg       0.92      0.91      0.91      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_20x70.txt 1 EU 
Loading data...
Spliting data...
Using n_neighbors=1
Using metric=euclidean
Fitting knn
Predicting...
Accuracy:  0.926
[[ 94   1   0   0   0   2   0   0   0   0]
 [  0  93   0   0   0   1   0   0   0   1]
 [  0   1 102   1   0   0   0   5   1   1]
 [  1   0   0  99   0   1   0   0   2   0]
 [  0   8   0   0  83   1   1   0   0   2]
 [  2   0   0   5   0  89   1   0   0   0]
 [  1   5   0   0   1   0  99   0   0   0]
 [  0   3   1   0   1   0   0  89   0   3]
 [  0   3   0   1   1   2   0   1  79   0]
 [  0   1   0   0   3   0   0   9   0  99]]
              precision    recall  f1-score   support

           0       0.96      0.97      0.96        97
           1       0.81      0.98      0.89        95
           2       0.99      0.92      0.95       111
           3       0.93      0.96      0.95       103
           4       0.93      0.87      0.90        95
           5       0.93      0.92      0.92        97
           6       0.98      0.93      0.96       106
           7       0.86      0.92      0.89        97
           8       0.96      0.91      0.93        87
           9       0.93      0.88      0.91       112

    accuracy                           0.93      1000
   macro avg       0.93      0.93      0.93      1000
weighted avg       0.93      0.93      0.93      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_20x70.txt 1 MA 
Loading data...
Spliting data...
Using n_neighbors=1
Using metric=manhattan
Fitting knn
Predicting...
Accuracy:  0.926
[[ 94   1   0   0   0   2   0   0   0   0]
 [  0  93   0   0   0   1   0   0   0   1]
 [  0   1 102   1   0   0   0   5   1   1]
 [  1   0   0  99   0   1   0   0   2   0]
 [  0   8   0   0  83   1   1   0   0   2]
 [  2   0   0   5   0  89   1   0   0   0]
 [  1   5   0   0   1   0  99   0   0   0]
 [  0   3   1   0   1   0   0  89   0   3]
 [  0   3   0   1   1   2   0   1  79   0]
 [  0   1   0   0   3   0   0   9   0  99]]
              precision    recall  f1-score   support

           0       0.96      0.97      0.96        97
           1       0.81      0.98      0.89        95
           2       0.99      0.92      0.95       111
           3       0.93      0.96      0.95       103
           4       0.93      0.87      0.90        95
           5       0.93      0.92      0.92        97
           6       0.98      0.93      0.96       106
           7       0.86      0.92      0.89        97
           8       0.96      0.91      0.93        87
           9       0.93      0.88      0.91       112

    accuracy                           0.93      1000
   macro avg       0.93      0.93      0.93      1000
weighted avg       0.93      0.93      0.93      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_20x70.txt 1 MI 
Loading data...
Spliting data...
Using n_neighbors=1
Using metric=minkowski
Fitting knn
Predicting...
Accuracy:  0.926
[[ 94   1   0   0   0   2   0   0   0   0]
 [  0  93   0   0   0   1   0   0   0   1]
 [  0   1 102   1   0   0   0   5   1   1]
 [  1   0   0  99   0   1   0   0   2   0]
 [  0   8   0   0  83   1   1   0   0   2]
 [  2   0   0   5   0  89   1   0   0   0]
 [  1   5   0   0   1   0  99   0   0   0]
 [  0   3   1   0   1   0   0  89   0   3]
 [  0   3   0   1   1   2   0   1  79   0]
 [  0   1   0   0   3   0   0   9   0  99]]
              precision    recall  f1-score   support

           0       0.96      0.97      0.96        97
           1       0.81      0.98      0.89        95
           2       0.99      0.92      0.95       111
           3       0.93      0.96      0.95       103
           4       0.93      0.87      0.90        95
           5       0.93      0.92      0.92        97
           6       0.98      0.93      0.96       106
           7       0.86      0.92      0.89        97
           8       0.96      0.91      0.93        87
           9       0.93      0.88      0.91       112

    accuracy                           0.93      1000
   macro avg       0.93      0.93      0.93      1000
weighted avg       0.93      0.93      0.93      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_20x70.txt 3 EU 
Loading data...
Spliting data...
Using n_neighbors=3
Using metric=euclidean
Fitting knn
Predicting...
Accuracy:  0.925
[[ 96   0   0   0   0   1   0   0   0   0]
 [  0  95   0   0   0   0   0   0   0   0]
 [  0   5 101   0   1   0   1   2   1   0]
 [  1   1   0 100   0   0   0   0   1   0]
 [  0  10   2   0  81   0   0   0   0   2]
 [  1   0   0   4   0  91   1   0   0   0]
 [  2   5   0   0   0   0  99   0   0   0]
 [  0   9   0   0   0   0   0  85   0   3]
 [  1   3   0   3   0   1   0   0  77   2]
 [  0   2   0   0   3   0   0   6   1 100]]
              precision    recall  f1-score   support

           0       0.95      0.99      0.97        97
           1       0.73      1.00      0.84        95
           2       0.98      0.91      0.94       111
           3       0.93      0.97      0.95       103
           4       0.95      0.85      0.90        95
           5       0.98      0.94      0.96        97
           6       0.98      0.93      0.96       106
           7       0.91      0.88      0.89        97
           8       0.96      0.89      0.92        87
           9       0.93      0.89      0.91       112

    accuracy                           0.93      1000
   macro avg       0.93      0.92      0.93      1000
weighted avg       0.93      0.93      0.93      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_20x70.txt 3 MA 
Loading data...
Spliting data...
Using n_neighbors=3
Using metric=manhattan
Fitting knn
Predicting...
Accuracy:  0.925
[[ 96   0   0   0   0   1   0   0   0   0]
 [  0  95   0   0   0   0   0   0   0   0]
 [  0   5 101   0   1   0   1   2   1   0]
 [  1   1   0 100   0   0   0   0   1   0]
 [  0  10   2   0  81   0   0   0   0   2]
 [  1   0   0   4   0  91   1   0   0   0]
 [  2   5   0   0   0   0  99   0   0   0]
 [  0   9   0   0   0   0   0  85   0   3]
 [  1   3   0   3   0   1   0   0  77   2]
 [  0   2   0   0   3   0   0   6   1 100]]
              precision    recall  f1-score   support

           0       0.95      0.99      0.97        97
           1       0.73      1.00      0.84        95
           2       0.98      0.91      0.94       111
           3       0.93      0.97      0.95       103
           4       0.95      0.85      0.90        95
           5       0.98      0.94      0.96        97
           6       0.98      0.93      0.96       106
           7       0.91      0.88      0.89        97
           8       0.96      0.89      0.92        87
           9       0.93      0.89      0.91       112

    accuracy                           0.93      1000
   macro avg       0.93      0.92      0.93      1000
weighted avg       0.93      0.93      0.93      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_20x70.txt 3 MI 
Loading data...
Spliting data...
Using n_neighbors=3
Using metric=minkowski
Fitting knn
Predicting...
Accuracy:  0.925
[[ 96   0   0   0   0   1   0   0   0   0]
 [  0  95   0   0   0   0   0   0   0   0]
 [  0   5 101   0   1   0   1   2   1   0]
 [  1   1   0 100   0   0   0   0   1   0]
 [  0  10   2   0  81   0   0   0   0   2]
 [  1   0   0   4   0  91   1   0   0   0]
 [  2   5   0   0   0   0  99   0   0   0]
 [  0   9   0   0   0   0   0  85   0   3]
 [  1   3   0   3   0   1   0   0  77   2]
 [  0   2   0   0   3   0   0   6   1 100]]
              precision    recall  f1-score   support

           0       0.95      0.99      0.97        97
           1       0.73      1.00      0.84        95
           2       0.98      0.91      0.94       111
           3       0.93      0.97      0.95       103
           4       0.95      0.85      0.90        95
           5       0.98      0.94      0.96        97
           6       0.98      0.93      0.96       106
           7       0.91      0.88      0.89        97
           8       0.96      0.89      0.92        87
           9       0.93      0.89      0.91       112

    accuracy                           0.93      1000
   macro avg       0.93      0.92      0.93      1000
weighted avg       0.93      0.93      0.93      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_20x70.txt 5 EU 
Loading data...
Spliting data...
Using n_neighbors=5
Using metric=euclidean
Fitting knn
Predicting...
Accuracy:  0.916
[[ 95   1   0   0   0   1   0   0   0   0]
 [  0  95   0   0   0   0   0   0   0   0]
 [  1   5  99   0   1   0   1   3   0   1]
 [  0   1   0  98   0   0   0   2   2   0]
 [  0  11   1   0  82   0   1   0   0   0]
 [  1   1   0   6   0  88   1   0   0   0]
 [  0   5   0   0   0   0 101   0   0   0]
 [  0   8   0   0   0   0   0  87   0   2]
 [  0   4   0   4   0   2   0   2  75   0]
 [  0   3   0   0   4   0   0   9   0  96]]
              precision    recall  f1-score   support

           0       0.98      0.98      0.98        97
           1       0.71      1.00      0.83        95
           2       0.99      0.89      0.94       111
           3       0.91      0.95      0.93       103
           4       0.94      0.86      0.90        95
           5       0.97      0.91      0.94        97
           6       0.97      0.95      0.96       106
           7       0.84      0.90      0.87        97
           8       0.97      0.86      0.91        87
           9       0.97      0.86      0.91       112

    accuracy                           0.92      1000
   macro avg       0.93      0.92      0.92      1000
weighted avg       0.93      0.92      0.92      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_20x70.txt 5 MA 
Loading data...
Spliting data...
Using n_neighbors=5
Using metric=manhattan
Fitting knn
Predicting...
Accuracy:  0.916
[[ 95   1   0   0   0   1   0   0   0   0]
 [  0  95   0   0   0   0   0   0   0   0]
 [  1   5  99   0   1   0   1   3   0   1]
 [  0   1   0  98   0   0   0   2   2   0]
 [  0  11   1   0  82   0   1   0   0   0]
 [  1   1   0   6   0  88   1   0   0   0]
 [  0   5   0   0   0   0 101   0   0   0]
 [  0   8   0   0   0   0   0  87   0   2]
 [  0   4   0   4   0   2   0   2  75   0]
 [  0   3   0   0   4   0   0   9   0  96]]
              precision    recall  f1-score   support

           0       0.98      0.98      0.98        97
           1       0.71      1.00      0.83        95
           2       0.99      0.89      0.94       111
           3       0.91      0.95      0.93       103
           4       0.94      0.86      0.90        95
           5       0.97      0.91      0.94        97
           6       0.97      0.95      0.96       106
           7       0.84      0.90      0.87        97
           8       0.97      0.86      0.91        87
           9       0.97      0.86      0.91       112

    accuracy                           0.92      1000
   macro avg       0.93      0.92      0.92      1000
weighted avg       0.93      0.92      0.92      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_20x70.txt 5 MI 
Loading data...
Spliting data...
Using n_neighbors=5
Using metric=minkowski
Fitting knn
Predicting...
Accuracy:  0.916
[[ 95   1   0   0   0   1   0   0   0   0]
 [  0  95   0   0   0   0   0   0   0   0]
 [  1   5  99   0   1   0   1   3   0   1]
 [  0   1   0  98   0   0   0   2   2   0]
 [  0  11   1   0  82   0   1   0   0   0]
 [  1   1   0   6   0  88   1   0   0   0]
 [  0   5   0   0   0   0 101   0   0   0]
 [  0   8   0   0   0   0   0  87   0   2]
 [  0   4   0   4   0   2   0   2  75   0]
 [  0   3   0   0   4   0   0   9   0  96]]
              precision    recall  f1-score   support

           0       0.98      0.98      0.98        97
           1       0.71      1.00      0.83        95
           2       0.99      0.89      0.94       111
           3       0.91      0.95      0.93       103
           4       0.94      0.86      0.90        95
           5       0.97      0.91      0.94        97
           6       0.97      0.95      0.96       106
           7       0.84      0.90      0.87        97
           8       0.97      0.86      0.91        87
           9       0.97      0.86      0.91       112

    accuracy                           0.92      1000
   macro avg       0.93      0.92      0.92      1000
weighted avg       0.93      0.92      0.92      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_30x40.txt 1 EU 
Loading data...
Spliting data...
Using n_neighbors=1
Using metric=euclidean
Fitting knn
Predicting...
Accuracy:  0.922
[[ 93   1   0   0   0   2   1   0   0   0]
 [  0  93   0   0   0   1   0   0   0   1]
 [  1   2 102   1   0   0   0   4   0   1]
 [  0   1   0  99   0   1   0   1   1   0]
 [  0   8   0   0  82   1   1   0   0   3]
 [  1   1   0   6   0  88   1   0   0   0]
 [  2   4   0   0   0   0  99   0   1   0]
 [  0   3   1   0   1   0   0  88   0   4]
 [  0   2   0   1   1   2   0   1  80   0]
 [  0   1   0   0   2   0   0  11   0  98]]
              precision    recall  f1-score   support

           0       0.96      0.96      0.96        97
           1       0.80      0.98      0.88        95
           2       0.99      0.92      0.95       111
           3       0.93      0.96      0.94       103
           4       0.95      0.86      0.91        95
           5       0.93      0.91      0.92        97
           6       0.97      0.93      0.95       106
           7       0.84      0.91      0.87        97
           8       0.98      0.92      0.95        87
           9       0.92      0.88      0.89       112

    accuracy                           0.92      1000
   macro avg       0.93      0.92      0.92      1000
weighted avg       0.93      0.92      0.92      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_30x40.txt 1 MA 
Loading data...
Spliting data...
Using n_neighbors=1
Using metric=manhattan
Fitting knn
Predicting...
Accuracy:  0.922
[[ 93   1   0   0   0   2   1   0   0   0]
 [  0  93   0   0   0   1   0   0   0   1]
 [  1   2 102   1   0   0   0   4   0   1]
 [  0   1   0  99   0   1   0   1   1   0]
 [  0   8   0   0  82   1   1   0   0   3]
 [  1   1   0   6   0  88   1   0   0   0]
 [  2   4   0   0   0   0  99   0   1   0]
 [  0   3   1   0   1   0   0  88   0   4]
 [  0   2   0   1   1   2   0   1  80   0]
 [  0   1   0   0   2   0   0  11   0  98]]
              precision    recall  f1-score   support

           0       0.96      0.96      0.96        97
           1       0.80      0.98      0.88        95
           2       0.99      0.92      0.95       111
           3       0.93      0.96      0.94       103
           4       0.95      0.86      0.91        95
           5       0.93      0.91      0.92        97
           6       0.97      0.93      0.95       106
           7       0.84      0.91      0.87        97
           8       0.98      0.92      0.95        87
           9       0.92      0.88      0.89       112

    accuracy                           0.92      1000
   macro avg       0.93      0.92      0.92      1000
weighted avg       0.93      0.92      0.92      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_30x40.txt 1 MI 
Loading data...
Spliting data...
Using n_neighbors=1
Using metric=minkowski
Fitting knn
Predicting...
Accuracy:  0.922
[[ 93   1   0   0   0   2   1   0   0   0]
 [  0  93   0   0   0   1   0   0   0   1]
 [  1   2 102   1   0   0   0   4   0   1]
 [  0   1   0  99   0   1   0   1   1   0]
 [  0   8   0   0  82   1   1   0   0   3]
 [  1   1   0   6   0  88   1   0   0   0]
 [  2   4   0   0   0   0  99   0   1   0]
 [  0   3   1   0   1   0   0  88   0   4]
 [  0   2   0   1   1   2   0   1  80   0]
 [  0   1   0   0   2   0   0  11   0  98]]
              precision    recall  f1-score   support

           0       0.96      0.96      0.96        97
           1       0.80      0.98      0.88        95
           2       0.99      0.92      0.95       111
           3       0.93      0.96      0.94       103
           4       0.95      0.86      0.91        95
           5       0.93      0.91      0.92        97
           6       0.97      0.93      0.95       106
           7       0.84      0.91      0.87        97
           8       0.98      0.92      0.95        87
           9       0.92      0.88      0.89       112

    accuracy                           0.92      1000
   macro avg       0.93      0.92      0.92      1000
weighted avg       0.93      0.92      0.92      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_30x40.txt 3 EU 
Loading data...
Spliting data...
Using n_neighbors=3
Using metric=euclidean
Fitting knn
Predicting...
Accuracy:  0.909
[[96  0  0  0  0  1  0  0  0  0]
 [ 0 94  0  0  0  0  0  0  0  1]
 [ 1  7 97  1  1  0  1  2  1  0]
 [ 0  1  0 97  0  2  0  2  1  0]
 [ 0 11  2  0 80  0  0  0  0  2]
 [ 1  1  0  6  0 88  1  0  0  0]
 [ 1  6  0  0  0  0 99  0  0  0]
 [ 1  8  0  0  0  0  0 85  0  3]
 [ 0  3  0  4  0  1  0  1 77  1]
 [ 0  1  0  0  5  0  0  9  1 96]]
              precision    recall  f1-score   support

           0       0.96      0.99      0.97        97
           1       0.71      0.99      0.83        95
           2       0.98      0.87      0.92       111
           3       0.90      0.94      0.92       103
           4       0.93      0.84      0.88        95
           5       0.96      0.91      0.93        97
           6       0.98      0.93      0.96       106
           7       0.86      0.88      0.87        97
           8       0.96      0.89      0.92        87
           9       0.93      0.86      0.89       112

    accuracy                           0.91      1000
   macro avg       0.92      0.91      0.91      1000
weighted avg       0.92      0.91      0.91      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_30x40.txt 3 MA 
Loading data...
Spliting data...
Using n_neighbors=3
Using metric=manhattan
Fitting knn
Predicting...
Accuracy:  0.909
[[96  0  0  0  0  1  0  0  0  0]
 [ 0 94  0  0  0  0  0  0  0  1]
 [ 1  7 97  1  1  0  1  2  1  0]
 [ 0  1  0 97  0  2  0  2  1  0]
 [ 0 11  2  0 80  0  0  0  0  2]
 [ 1  1  0  6  0 88  1  0  0  0]
 [ 1  6  0  0  0  0 99  0  0  0]
 [ 1  8  0  0  0  0  0 85  0  3]
 [ 0  3  0  4  0  1  0  1 77  1]
 [ 0  1  0  0  5  0  0  9  1 96]]
              precision    recall  f1-score   support

           0       0.96      0.99      0.97        97
           1       0.71      0.99      0.83        95
           2       0.98      0.87      0.92       111
           3       0.90      0.94      0.92       103
           4       0.93      0.84      0.88        95
           5       0.96      0.91      0.93        97
           6       0.98      0.93      0.96       106
           7       0.86      0.88      0.87        97
           8       0.96      0.89      0.92        87
           9       0.93      0.86      0.89       112

    accuracy                           0.91      1000
   macro avg       0.92      0.91      0.91      1000
weighted avg       0.92      0.91      0.91      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_30x40.txt 3 MI 
Loading data...
Spliting data...
Using n_neighbors=3
Using metric=minkowski
Fitting knn
Predicting...
Accuracy:  0.909
[[96  0  0  0  0  1  0  0  0  0]
 [ 0 94  0  0  0  0  0  0  0  1]
 [ 1  7 97  1  1  0  1  2  1  0]
 [ 0  1  0 97  0  2  0  2  1  0]
 [ 0 11  2  0 80  0  0  0  0  2]
 [ 1  1  0  6  0 88  1  0  0  0]
 [ 1  6  0  0  0  0 99  0  0  0]
 [ 1  8  0  0  0  0  0 85  0  3]
 [ 0  3  0  4  0  1  0  1 77  1]
 [ 0  1  0  0  5  0  0  9  1 96]]
              precision    recall  f1-score   support

           0       0.96      0.99      0.97        97
           1       0.71      0.99      0.83        95
           2       0.98      0.87      0.92       111
           3       0.90      0.94      0.92       103
           4       0.93      0.84      0.88        95
           5       0.96      0.91      0.93        97
           6       0.98      0.93      0.96       106
           7       0.86      0.88      0.87        97
           8       0.96      0.89      0.92        87
           9       0.93      0.86      0.89       112

    accuracy                           0.91      1000
   macro avg       0.92      0.91      0.91      1000
weighted avg       0.92      0.91      0.91      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_30x40.txt 5 EU 
Loading data...
Spliting data...
Using n_neighbors=5
Using metric=euclidean
Fitting knn
Predicting...
Accuracy:  0.908
[[ 95   1   0   0   0   1   0   0   0   0]
 [  0  94   0   0   0   0   0   0   0   1]
 [  0   7  99   0   1   0   1   3   0   0]
 [  0   1   0  97   0   1   0   2   2   0]
 [  0  11   1   0  81   0   1   0   0   1]
 [  1   1   0   6   0  88   1   0   0   0]
 [  0   6   0   0   0   0 100   0   0   0]
 [  0   9   0   0   1   0   0  84   0   3]
 [  0   4   0   4   0   1   0   2  75   1]
 [  0   2   0   0   4   0   0  11   0  95]]
              precision    recall  f1-score   support

           0       0.99      0.98      0.98        97
           1       0.69      0.99      0.81        95
           2       0.99      0.89      0.94       111
           3       0.91      0.94      0.92       103
           4       0.93      0.85      0.89        95
           5       0.97      0.91      0.94        97
           6       0.97      0.94      0.96       106
           7       0.82      0.87      0.84        97
           8       0.97      0.86      0.91        87
           9       0.94      0.85      0.89       112

    accuracy                           0.91      1000
   macro avg       0.92      0.91      0.91      1000
weighted avg       0.92      0.91      0.91      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_30x40.txt 5 MA 
Loading data...
Spliting data...
Using n_neighbors=5
Using metric=manhattan
Fitting knn
Predicting...
Accuracy:  0.908
[[ 95   1   0   0   0   1   0   0   0   0]
 [  0  94   0   0   0   0   0   0   0   1]
 [  0   7  99   0   1   0   1   3   0   0]
 [  0   1   0  97   0   1   0   2   2   0]
 [  0  11   1   0  81   0   1   0   0   1]
 [  1   1   0   6   0  88   1   0   0   0]
 [  0   6   0   0   0   0 100   0   0   0]
 [  0   9   0   0   1   0   0  84   0   3]
 [  0   4   0   4   0   1   0   2  75   1]
 [  0   2   0   0   4   0   0  11   0  95]]
              precision    recall  f1-score   support

           0       0.99      0.98      0.98        97
           1       0.69      0.99      0.81        95
           2       0.99      0.89      0.94       111
           3       0.91      0.94      0.92       103
           4       0.93      0.85      0.89        95
           5       0.97      0.91      0.94        97
           6       0.97      0.94      0.96       106
           7       0.82      0.87      0.84        97
           8       0.97      0.86      0.91        87
           9       0.94      0.85      0.89       112

    accuracy                           0.91      1000
   macro avg       0.92      0.91      0.91      1000
weighted avg       0.92      0.91      0.91      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_30x40.txt 5 MI 
Loading data...
Spliting data...
Using n_neighbors=5
Using metric=minkowski
Fitting knn
Predicting...
Accuracy:  0.908
[[ 95   1   0   0   0   1   0   0   0   0]
 [  0  94   0   0   0   0   0   0   0   1]
 [  0   7  99   0   1   0   1   3   0   0]
 [  0   1   0  97   0   1   0   2   2   0]
 [  0  11   1   0  81   0   1   0   0   1]
 [  1   1   0   6   0  88   1   0   0   0]
 [  0   6   0   0   0   0 100   0   0   0]
 [  0   9   0   0   1   0   0  84   0   3]
 [  0   4   0   4   0   1   0   2  75   1]
 [  0   2   0   0   4   0   0  11   0  95]]
              precision    recall  f1-score   support

           0       0.99      0.98      0.98        97
           1       0.69      0.99      0.81        95
           2       0.99      0.89      0.94       111
           3       0.91      0.94      0.92       103
           4       0.93      0.85      0.89        95
           5       0.97      0.91      0.94        97
           6       0.97      0.94      0.96       106
           7       0.82      0.87      0.84        97
           8       0.97      0.86      0.91        87
           9       0.94      0.85      0.89       112

    accuracy                           0.91      1000
   macro avg       0.92      0.91      0.91      1000
weighted avg       0.92      0.91      0.91      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_32x40.txt 1 EU 
Loading data...
Spliting data...
Using n_neighbors=1
Using metric=euclidean
Fitting knn
Predicting...
Accuracy:  0.927
[[ 94   1   0   0   0   1   1   0   0   0]
 [  0  93   0   0   0   1   0   0   0   1]
 [  0   1 103   1   0   0   0   5   0   1]
 [  1   0   0  99   0   1   0   1   1   0]
 [  0   8   0   0  82   1   1   0   0   3]
 [  1   1   0   6   0  88   1   0   0   0]
 [  0   5   0   0   0   0 101   0   0   0]
 [  0   3   1   0   0   0   0  89   0   4]
 [  0   4   0   1   0   2   0   1  79   0]
 [  0   0   0   0   1   0   0  12   0  99]]
              precision    recall  f1-score   support

           0       0.98      0.97      0.97        97
           1       0.80      0.98      0.88        95
           2       0.99      0.93      0.96       111
           3       0.93      0.96      0.94       103
           4       0.99      0.86      0.92        95
           5       0.94      0.91      0.92        97
           6       0.97      0.95      0.96       106
           7       0.82      0.92      0.87        97
           8       0.99      0.91      0.95        87
           9       0.92      0.88      0.90       112

    accuracy                           0.93      1000
   macro avg       0.93      0.93      0.93      1000
weighted avg       0.93      0.93      0.93      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_32x40.txt 1 MA 
Loading data...
Spliting data...
Using n_neighbors=1
Using metric=manhattan
Fitting knn
Predicting...
Accuracy:  0.927
[[ 94   1   0   0   0   1   1   0   0   0]
 [  0  93   0   0   0   1   0   0   0   1]
 [  0   1 103   1   0   0   0   5   0   1]
 [  1   0   0  99   0   1   0   1   1   0]
 [  0   8   0   0  82   1   1   0   0   3]
 [  1   1   0   6   0  88   1   0   0   0]
 [  0   5   0   0   0   0 101   0   0   0]
 [  0   3   1   0   0   0   0  89   0   4]
 [  0   4   0   1   0   2   0   1  79   0]
 [  0   0   0   0   1   0   0  12   0  99]]
              precision    recall  f1-score   support

           0       0.98      0.97      0.97        97
           1       0.80      0.98      0.88        95
           2       0.99      0.93      0.96       111
           3       0.93      0.96      0.94       103
           4       0.99      0.86      0.92        95
           5       0.94      0.91      0.92        97
           6       0.97      0.95      0.96       106
           7       0.82      0.92      0.87        97
           8       0.99      0.91      0.95        87
           9       0.92      0.88      0.90       112

    accuracy                           0.93      1000
   macro avg       0.93      0.93      0.93      1000
weighted avg       0.93      0.93      0.93      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_32x40.txt 1 MI 
Loading data...
Spliting data...
Using n_neighbors=1
Using metric=minkowski
Fitting knn
Predicting...
Accuracy:  0.927
[[ 94   1   0   0   0   1   1   0   0   0]
 [  0  93   0   0   0   1   0   0   0   1]
 [  0   1 103   1   0   0   0   5   0   1]
 [  1   0   0  99   0   1   0   1   1   0]
 [  0   8   0   0  82   1   1   0   0   3]
 [  1   1   0   6   0  88   1   0   0   0]
 [  0   5   0   0   0   0 101   0   0   0]
 [  0   3   1   0   0   0   0  89   0   4]
 [  0   4   0   1   0   2   0   1  79   0]
 [  0   0   0   0   1   0   0  12   0  99]]
              precision    recall  f1-score   support

           0       0.98      0.97      0.97        97
           1       0.80      0.98      0.88        95
           2       0.99      0.93      0.96       111
           3       0.93      0.96      0.94       103
           4       0.99      0.86      0.92        95
           5       0.94      0.91      0.92        97
           6       0.97      0.95      0.96       106
           7       0.82      0.92      0.87        97
           8       0.99      0.91      0.95        87
           9       0.92      0.88      0.90       112

    accuracy                           0.93      1000
   macro avg       0.93      0.93      0.93      1000
weighted avg       0.93      0.93      0.93      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_32x40.txt 3 EU 
Loading data...
Spliting data...
Using n_neighbors=3
Using metric=euclidean
Fitting knn
Predicting...
Accuracy:  0.913
[[96  0  0  0  0  1  0  0  0  0]
 [ 0 94  0  0  0  0  0  0  0  1]
 [ 0  8 97  1  1  0  1  3  0  0]
 [ 1  0  1 97  0  2  0  1  1  0]
 [ 0 11  2  0 82  0  0  0  0  0]
 [ 1  1  0  4  0 90  1  0  0  0]
 [ 2  5  0  0  0  0 99  0  0  0]
 [ 0  8  0  0  1  0  0 85  0  3]
 [ 0  2  1  5  1  1  0  1 76  0]
 [ 0  1  0  0  3  0  0 10  1 97]]
              precision    recall  f1-score   support

           0       0.96      0.99      0.97        97
           1       0.72      0.99      0.84        95
           2       0.96      0.87      0.92       111
           3       0.91      0.94      0.92       103
           4       0.93      0.86      0.90        95
           5       0.96      0.93      0.94        97
           6       0.98      0.93      0.96       106
           7       0.85      0.88      0.86        97
           8       0.97      0.87      0.92        87
           9       0.96      0.87      0.91       112

    accuracy                           0.91      1000
   macro avg       0.92      0.91      0.91      1000
weighted avg       0.92      0.91      0.91      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_32x40.txt 3 MA 
Loading data...
Spliting data...
Using n_neighbors=3
Using metric=manhattan
Fitting knn
Predicting...
Accuracy:  0.913
[[96  0  0  0  0  1  0  0  0  0]
 [ 0 94  0  0  0  0  0  0  0  1]
 [ 0  8 97  1  1  0  1  3  0  0]
 [ 1  0  1 97  0  2  0  1  1  0]
 [ 0 11  2  0 82  0  0  0  0  0]
 [ 1  1  0  4  0 90  1  0  0  0]
 [ 2  5  0  0  0  0 99  0  0  0]
 [ 0  8  0  0  1  0  0 85  0  3]
 [ 0  2  1  5  1  1  0  1 76  0]
 [ 0  1  0  0  3  0  0 10  1 97]]
              precision    recall  f1-score   support

           0       0.96      0.99      0.97        97
           1       0.72      0.99      0.84        95
           2       0.96      0.87      0.92       111
           3       0.91      0.94      0.92       103
           4       0.93      0.86      0.90        95
           5       0.96      0.93      0.94        97
           6       0.98      0.93      0.96       106
           7       0.85      0.88      0.86        97
           8       0.97      0.87      0.92        87
           9       0.96      0.87      0.91       112

    accuracy                           0.91      1000
   macro avg       0.92      0.91      0.91      1000
weighted avg       0.92      0.91      0.91      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_32x40.txt 3 MI 
Loading data...
Spliting data...
Using n_neighbors=3
Using metric=minkowski
Fitting knn
Predicting...
Accuracy:  0.913
[[96  0  0  0  0  1  0  0  0  0]
 [ 0 94  0  0  0  0  0  0  0  1]
 [ 0  8 97  1  1  0  1  3  0  0]
 [ 1  0  1 97  0  2  0  1  1  0]
 [ 0 11  2  0 82  0  0  0  0  0]
 [ 1  1  0  4  0 90  1  0  0  0]
 [ 2  5  0  0  0  0 99  0  0  0]
 [ 0  8  0  0  1  0  0 85  0  3]
 [ 0  2  1  5  1  1  0  1 76  0]
 [ 0  1  0  0  3  0  0 10  1 97]]
              precision    recall  f1-score   support

           0       0.96      0.99      0.97        97
           1       0.72      0.99      0.84        95
           2       0.96      0.87      0.92       111
           3       0.91      0.94      0.92       103
           4       0.93      0.86      0.90        95
           5       0.96      0.93      0.94        97
           6       0.98      0.93      0.96       106
           7       0.85      0.88      0.86        97
           8       0.97      0.87      0.92        87
           9       0.96      0.87      0.91       112

    accuracy                           0.91      1000
   macro avg       0.92      0.91      0.91      1000
weighted avg       0.92      0.91      0.91      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_32x40.txt 5 EU 
Loading data...
Spliting data...
Using n_neighbors=5
Using metric=euclidean
Fitting knn
Predicting...
Accuracy:  0.905
[[ 95   1   0   0   0   1   0   0   0   0]
 [  0  94   0   0   0   0   0   1   0   0]
 [  0   8  98   0   1   0   1   3   0   0]
 [  0   1   0  97   0   1   0   2   2   0]
 [  0  11   1   0  82   0   0   0   0   1]
 [  1   1   0   6   0  88   1   0   0   0]
 [  0   6   0   0   0   0 100   0   0   0]
 [  0   8   0   0   1   0   0  84   0   4]
 [  0   6   0   5   0   1   0   3  70   2]
 [  0   2   0   0   4   0   0   9   0  97]]
              precision    recall  f1-score   support

           0       0.99      0.98      0.98        97
           1       0.68      0.99      0.81        95
           2       0.99      0.88      0.93       111
           3       0.90      0.94      0.92       103
           4       0.93      0.86      0.90        95
           5       0.97      0.91      0.94        97
           6       0.98      0.94      0.96       106
           7       0.82      0.87      0.84        97
           8       0.97      0.80      0.88        87
           9       0.93      0.87      0.90       112

    accuracy                           0.91      1000
   macro avg       0.92      0.90      0.91      1000
weighted avg       0.92      0.91      0.91      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_32x40.txt 5 MA 
Loading data...
Spliting data...
Using n_neighbors=5
Using metric=manhattan
Fitting knn
Predicting...
Accuracy:  0.905
[[ 95   1   0   0   0   1   0   0   0   0]
 [  0  94   0   0   0   0   0   1   0   0]
 [  0   8  98   0   1   0   1   3   0   0]
 [  0   1   0  97   0   1   0   2   2   0]
 [  0  11   1   0  82   0   0   0   0   1]
 [  1   1   0   6   0  88   1   0   0   0]
 [  0   6   0   0   0   0 100   0   0   0]
 [  0   8   0   0   1   0   0  84   0   4]
 [  0   6   0   5   0   1   0   3  70   2]
 [  0   2   0   0   4   0   0   9   0  97]]
              precision    recall  f1-score   support

           0       0.99      0.98      0.98        97
           1       0.68      0.99      0.81        95
           2       0.99      0.88      0.93       111
           3       0.90      0.94      0.92       103
           4       0.93      0.86      0.90        95
           5       0.97      0.91      0.94        97
           6       0.98      0.94      0.96       106
           7       0.82      0.87      0.84        97
           8       0.97      0.80      0.88        87
           9       0.93      0.87      0.90       112

    accuracy                           0.91      1000
   macro avg       0.92      0.90      0.91      1000
weighted avg       0.92      0.91      0.91      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_32x40.txt 5 MI 
Loading data...
Spliting data...
Using n_neighbors=5
Using metric=minkowski
Fitting knn
Predicting...
Accuracy:  0.905
[[ 95   1   0   0   0   1   0   0   0   0]
 [  0  94   0   0   0   0   0   1   0   0]
 [  0   8  98   0   1   0   1   3   0   0]
 [  0   1   0  97   0   1   0   2   2   0]
 [  0  11   1   0  82   0   0   0   0   1]
 [  1   1   0   6   0  88   1   0   0   0]
 [  0   6   0   0   0   0 100   0   0   0]
 [  0   8   0   0   1   0   0  84   0   4]
 [  0   6   0   5   0   1   0   3  70   2]
 [  0   2   0   0   4   0   0   9   0  97]]
              precision    recall  f1-score   support

           0       0.99      0.98      0.98        97
           1       0.68      0.99      0.81        95
           2       0.99      0.88      0.93       111
           3       0.90      0.94      0.92       103
           4       0.93      0.86      0.90        95
           5       0.97      0.91      0.94        97
           6       0.98      0.94      0.96       106
           7       0.82      0.87      0.84        97
           8       0.97      0.80      0.88        87
           9       0.93      0.87      0.90       112

    accuracy                           0.91      1000
   macro avg       0.92      0.90      0.91      1000
weighted avg       0.92      0.91      0.91      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_36x46.txt 1 EU 
Loading data...
Spliting data...
Using n_neighbors=1
Using metric=euclidean
Fitting knn
Predicting...
Accuracy:  0.923
[[ 95   0   0   1   0   1   0   0   0   0]
 [  0  93   0   0   0   1   0   0   0   1]
 [  1   0 101   1   0   0   0   5   1   2]
 [  0   1   0  97   0   1   0   1   3   0]
 [  0   8   0   0  83   0   1   0   0   3]
 [  1   0   0   7   0  88   1   0   0   0]
 [  1   4   0   0   0   0 100   0   1   0]
 [  0   3   1   0   1   0   0  88   0   4]
 [  0   4   0   1   1   2   0   1  78   0]
 [  0   1   0   0   1   0   0  10   0 100]]
              precision    recall  f1-score   support

           0       0.97      0.98      0.97        97
           1       0.82      0.98      0.89        95
           2       0.99      0.91      0.95       111
           3       0.91      0.94      0.92       103
           4       0.97      0.87      0.92        95
           5       0.95      0.91      0.93        97
           6       0.98      0.94      0.96       106
           7       0.84      0.91      0.87        97
           8       0.94      0.90      0.92        87
           9       0.91      0.89      0.90       112

    accuracy                           0.92      1000
   macro avg       0.93      0.92      0.92      1000
weighted avg       0.93      0.92      0.92      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_36x46.txt 1 MA 
Loading data...
Spliting data...
Using n_neighbors=1
Using metric=manhattan
Fitting knn
Predicting...
Accuracy:  0.923
[[ 95   0   0   1   0   1   0   0   0   0]
 [  0  93   0   0   0   1   0   0   0   1]
 [  1   0 101   1   0   0   0   5   1   2]
 [  0   1   0  97   0   1   0   1   3   0]
 [  0   8   0   0  83   0   1   0   0   3]
 [  1   0   0   7   0  88   1   0   0   0]
 [  1   4   0   0   0   0 100   0   1   0]
 [  0   3   1   0   1   0   0  88   0   4]
 [  0   4   0   1   1   2   0   1  78   0]
 [  0   1   0   0   1   0   0  10   0 100]]
              precision    recall  f1-score   support

           0       0.97      0.98      0.97        97
           1       0.82      0.98      0.89        95
           2       0.99      0.91      0.95       111
           3       0.91      0.94      0.92       103
           4       0.97      0.87      0.92        95
           5       0.95      0.91      0.93        97
           6       0.98      0.94      0.96       106
           7       0.84      0.91      0.87        97
           8       0.94      0.90      0.92        87
           9       0.91      0.89      0.90       112

    accuracy                           0.92      1000
   macro avg       0.93      0.92      0.92      1000
weighted avg       0.93      0.92      0.92      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_36x46.txt 1 MI 
Loading data...
Spliting data...
Using n_neighbors=1
Using metric=minkowski
Fitting knn
Predicting...
Accuracy:  0.923
[[ 95   0   0   1   0   1   0   0   0   0]
 [  0  93   0   0   0   1   0   0   0   1]
 [  1   0 101   1   0   0   0   5   1   2]
 [  0   1   0  97   0   1   0   1   3   0]
 [  0   8   0   0  83   0   1   0   0   3]
 [  1   0   0   7   0  88   1   0   0   0]
 [  1   4   0   0   0   0 100   0   1   0]
 [  0   3   1   0   1   0   0  88   0   4]
 [  0   4   0   1   1   2   0   1  78   0]
 [  0   1   0   0   1   0   0  10   0 100]]
              precision    recall  f1-score   support

           0       0.97      0.98      0.97        97
           1       0.82      0.98      0.89        95
           2       0.99      0.91      0.95       111
           3       0.91      0.94      0.92       103
           4       0.97      0.87      0.92        95
           5       0.95      0.91      0.93        97
           6       0.98      0.94      0.96       106
           7       0.84      0.91      0.87        97
           8       0.94      0.90      0.92        87
           9       0.91      0.89      0.90       112

    accuracy                           0.92      1000
   macro avg       0.93      0.92      0.92      1000
weighted avg       0.93      0.92      0.92      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_36x46.txt 3 EU 
Loading data...
Spliting data...
Using n_neighbors=3
Using metric=euclidean
Fitting knn
Predicting...
Accuracy:  0.919
[[ 95   1   0   0   0   1   0   0   0   0]
 [  0  95   0   0   0   0   0   0   0   0]
 [  0   5 101   0   1   0   1   3   0   0]
 [  0   1   0  98   0   1   0   1   2   0]
 [  0  10   2   0  82   0   0   0   0   1]
 [  1   1   0   6   0  88   1   0   0   0]
 [  0   5   0   0   0   0 101   0   0   0]
 [  1   8   0   0   0   0   0  86   0   2]
 [  0   4   0   3   0   1   0   2  76   1]
 [  0   1   0   0   5   0   0   8   1  97]]
              precision    recall  f1-score   support

           0       0.98      0.98      0.98        97
           1       0.73      1.00      0.84        95
           2       0.98      0.91      0.94       111
           3       0.92      0.95      0.93       103
           4       0.93      0.86      0.90        95
           5       0.97      0.91      0.94        97
           6       0.98      0.95      0.97       106
           7       0.86      0.89      0.87        97
           8       0.96      0.87      0.92        87
           9       0.96      0.87      0.91       112

    accuracy                           0.92      1000
   macro avg       0.93      0.92      0.92      1000
weighted avg       0.93      0.92      0.92      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_36x46.txt 3 MA 
Loading data...
Spliting data...
Using n_neighbors=3
Using metric=manhattan
Fitting knn
Predicting...
Accuracy:  0.919
[[ 95   1   0   0   0   1   0   0   0   0]
 [  0  95   0   0   0   0   0   0   0   0]
 [  0   5 101   0   1   0   1   3   0   0]
 [  0   1   0  98   0   1   0   1   2   0]
 [  0  10   2   0  82   0   0   0   0   1]
 [  1   1   0   6   0  88   1   0   0   0]
 [  0   5   0   0   0   0 101   0   0   0]
 [  1   8   0   0   0   0   0  86   0   2]
 [  0   4   0   3   0   1   0   2  76   1]
 [  0   1   0   0   5   0   0   8   1  97]]
              precision    recall  f1-score   support

           0       0.98      0.98      0.98        97
           1       0.73      1.00      0.84        95
           2       0.98      0.91      0.94       111
           3       0.92      0.95      0.93       103
           4       0.93      0.86      0.90        95
           5       0.97      0.91      0.94        97
           6       0.98      0.95      0.97       106
           7       0.86      0.89      0.87        97
           8       0.96      0.87      0.92        87
           9       0.96      0.87      0.91       112

    accuracy                           0.92      1000
   macro avg       0.93      0.92      0.92      1000
weighted avg       0.93      0.92      0.92      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_36x46.txt 3 MI 
Loading data...
Spliting data...
Using n_neighbors=3
Using metric=minkowski
Fitting knn
Predicting...
Accuracy:  0.919
[[ 95   1   0   0   0   1   0   0   0   0]
 [  0  95   0   0   0   0   0   0   0   0]
 [  0   5 101   0   1   0   1   3   0   0]
 [  0   1   0  98   0   1   0   1   2   0]
 [  0  10   2   0  82   0   0   0   0   1]
 [  1   1   0   6   0  88   1   0   0   0]
 [  0   5   0   0   0   0 101   0   0   0]
 [  1   8   0   0   0   0   0  86   0   2]
 [  0   4   0   3   0   1   0   2  76   1]
 [  0   1   0   0   5   0   0   8   1  97]]
              precision    recall  f1-score   support

           0       0.98      0.98      0.98        97
           1       0.73      1.00      0.84        95
           2       0.98      0.91      0.94       111
           3       0.92      0.95      0.93       103
           4       0.93      0.86      0.90        95
           5       0.97      0.91      0.94        97
           6       0.98      0.95      0.97       106
           7       0.86      0.89      0.87        97
           8       0.96      0.87      0.92        87
           9       0.96      0.87      0.91       112

    accuracy                           0.92      1000
   macro avg       0.93      0.92      0.92      1000
weighted avg       0.93      0.92      0.92      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_36x46.txt 5 EU 
Loading data...
Spliting data...
Using n_neighbors=5
Using metric=euclidean
Fitting knn
Predicting...
Accuracy:  0.912
[[ 95   1   0   0   0   1   0   0   0   0]
 [  0  94   0   0   0   0   0   0   0   1]
 [  0   6 100   0   0   0   1   3   0   1]
 [  0   1   0  99   0   0   0   1   2   0]
 [  0  10   1   0  83   0   1   0   0   0]
 [  1   1   0   7   0  87   1   0   0   0]
 [  0   6   0   0   0   0 100   0   0   0]
 [  0   8   0   0   1   0   0  85   0   3]
 [  0   6   0   3   0   1   0   2  74   1]
 [  0   2   0   0   5   0   0  10   0  95]]
              precision    recall  f1-score   support

           0       0.99      0.98      0.98        97
           1       0.70      0.99      0.82        95
           2       0.99      0.90      0.94       111
           3       0.91      0.96      0.93       103
           4       0.93      0.87      0.90        95
           5       0.98      0.90      0.94        97
           6       0.97      0.94      0.96       106
           7       0.84      0.88      0.86        97
           8       0.97      0.85      0.91        87
           9       0.94      0.85      0.89       112

    accuracy                           0.91      1000
   macro avg       0.92      0.91      0.91      1000
weighted avg       0.92      0.91      0.91      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_36x46.txt 5 MA 
Loading data...
Spliting data...
Using n_neighbors=5
Using metric=manhattan
Fitting knn
Predicting...
Accuracy:  0.912
[[ 95   1   0   0   0   1   0   0   0   0]
 [  0  94   0   0   0   0   0   0   0   1]
 [  0   6 100   0   0   0   1   3   0   1]
 [  0   1   0  99   0   0   0   1   2   0]
 [  0  10   1   0  83   0   1   0   0   0]
 [  1   1   0   7   0  87   1   0   0   0]
 [  0   6   0   0   0   0 100   0   0   0]
 [  0   8   0   0   1   0   0  85   0   3]
 [  0   6   0   3   0   1   0   2  74   1]
 [  0   2   0   0   5   0   0  10   0  95]]
              precision    recall  f1-score   support

           0       0.99      0.98      0.98        97
           1       0.70      0.99      0.82        95
           2       0.99      0.90      0.94       111
           3       0.91      0.96      0.93       103
           4       0.93      0.87      0.90        95
           5       0.98      0.90      0.94        97
           6       0.97      0.94      0.96       106
           7       0.84      0.88      0.86        97
           8       0.97      0.85      0.91        87
           9       0.94      0.85      0.89       112

    accuracy                           0.91      1000
   macro avg       0.92      0.91      0.91      1000
weighted avg       0.92      0.91      0.91      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_36x46.txt 5 MI 
Loading data...
Spliting data...
Using n_neighbors=5
Using metric=minkowski
Fitting knn
Predicting...
Accuracy:  0.912
[[ 95   1   0   0   0   1   0   0   0   0]
 [  0  94   0   0   0   0   0   0   0   1]
 [  0   6 100   0   0   0   1   3   0   1]
 [  0   1   0  99   0   0   0   1   2   0]
 [  0  10   1   0  83   0   1   0   0   0]
 [  1   1   0   7   0  87   1   0   0   0]
 [  0   6   0   0   0   0 100   0   0   0]
 [  0   8   0   0   1   0   0  85   0   3]
 [  0   6   0   3   0   1   0   2  74   1]
 [  0   2   0   0   5   0   0  10   0  95]]
              precision    recall  f1-score   support

           0       0.99      0.98      0.98        97
           1       0.70      0.99      0.82        95
           2       0.99      0.90      0.94       111
           3       0.91      0.96      0.93       103
           4       0.93      0.87      0.90        95
           5       0.98      0.90      0.94        97
           6       0.97      0.94      0.96       106
           7       0.84      0.88      0.86        97
           8       0.97      0.85      0.91        87
           9       0.94      0.85      0.89       112

    accuracy                           0.91      1000
   macro avg       0.92      0.91      0.91      1000
weighted avg       0.92      0.91      0.91      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_37x47.txt 1 EU 
Loading data...
Spliting data...
Using n_neighbors=1
Using metric=euclidean
Fitting knn
Predicting...
Accuracy:  0.93
[[ 94   0   0   1   0   1   1   0   0   0]
 [  0  93   0   0   0   1   0   0   0   1]
 [  1   1 102   1   0   0   0   4   1   1]
 [  0   1   0 100   0   1   0   0   1   0]
 [  0   8   0   0  83   1   1   0   0   2]
 [  1   0   0   6   0  89   0   0   1   0]
 [  2   5   0   0   0   0  99   0   0   0]
 [  0   3   1   0   0   0   0  90   0   3]
 [  0   3   0   1   1   2   0   1  79   0]
 [  0   1   0   0   1   0   0   9   0 101]]
              precision    recall  f1-score   support

           0       0.96      0.97      0.96        97
           1       0.81      0.98      0.89        95
           2       0.99      0.92      0.95       111
           3       0.92      0.97      0.94       103
           4       0.98      0.87      0.92        95
           5       0.94      0.92      0.93        97
           6       0.98      0.93      0.96       106
           7       0.87      0.93      0.90        97
           8       0.96      0.91      0.93        87
           9       0.94      0.90      0.92       112

    accuracy                           0.93      1000
   macro avg       0.93      0.93      0.93      1000
weighted avg       0.93      0.93      0.93      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_37x47.txt 1 MA 
Loading data...
Spliting data...
Using n_neighbors=1
Using metric=manhattan
Fitting knn
Predicting...
Accuracy:  0.93
[[ 94   0   0   1   0   1   1   0   0   0]
 [  0  93   0   0   0   1   0   0   0   1]
 [  1   1 102   1   0   0   0   4   1   1]
 [  0   1   0 100   0   1   0   0   1   0]
 [  0   8   0   0  83   1   1   0   0   2]
 [  1   0   0   6   0  89   0   0   1   0]
 [  2   5   0   0   0   0  99   0   0   0]
 [  0   3   1   0   0   0   0  90   0   3]
 [  0   3   0   1   1   2   0   1  79   0]
 [  0   1   0   0   1   0   0   9   0 101]]
              precision    recall  f1-score   support

           0       0.96      0.97      0.96        97
           1       0.81      0.98      0.89        95
           2       0.99      0.92      0.95       111
           3       0.92      0.97      0.94       103
           4       0.98      0.87      0.92        95
           5       0.94      0.92      0.93        97
           6       0.98      0.93      0.96       106
           7       0.87      0.93      0.90        97
           8       0.96      0.91      0.93        87
           9       0.94      0.90      0.92       112

    accuracy                           0.93      1000
   macro avg       0.93      0.93      0.93      1000
weighted avg       0.93      0.93      0.93      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_37x47.txt 1 MI 
Loading data...
Spliting data...
Using n_neighbors=1
Using metric=minkowski
Fitting knn
Predicting...
Accuracy:  0.93
[[ 94   0   0   1   0   1   1   0   0   0]
 [  0  93   0   0   0   1   0   0   0   1]
 [  1   1 102   1   0   0   0   4   1   1]
 [  0   1   0 100   0   1   0   0   1   0]
 [  0   8   0   0  83   1   1   0   0   2]
 [  1   0   0   6   0  89   0   0   1   0]
 [  2   5   0   0   0   0  99   0   0   0]
 [  0   3   1   0   0   0   0  90   0   3]
 [  0   3   0   1   1   2   0   1  79   0]
 [  0   1   0   0   1   0   0   9   0 101]]
              precision    recall  f1-score   support

           0       0.96      0.97      0.96        97
           1       0.81      0.98      0.89        95
           2       0.99      0.92      0.95       111
           3       0.92      0.97      0.94       103
           4       0.98      0.87      0.92        95
           5       0.94      0.92      0.93        97
           6       0.98      0.93      0.96       106
           7       0.87      0.93      0.90        97
           8       0.96      0.91      0.93        87
           9       0.94      0.90      0.92       112

    accuracy                           0.93      1000
   macro avg       0.93      0.93      0.93      1000
weighted avg       0.93      0.93      0.93      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_37x47.txt 3 EU 
Loading data...
Spliting data...
Using n_neighbors=3
Using metric=euclidean
Fitting knn
Predicting...
Accuracy:  0.92
[[ 96   0   0   0   0   1   0   0   0   0]
 [  0  95   0   0   0   0   0   0   0   0]
 [  1   4 101   0   1   0   1   3   0   0]
 [  0   1   0  99   0   1   0   1   1   0]
 [  0  11   2   0  82   0   0   0   0   0]
 [  1   1   0   7   0  87   1   0   0   0]
 [  2   5   0   0   0   0  99   0   0   0]
 [  0   8   0   0   0   0   0  86   0   3]
 [  0   4   0   3   0   1   0   1  78   0]
 [  0   1   0   0   5   0   0   8   1  97]]
              precision    recall  f1-score   support

           0       0.96      0.99      0.97        97
           1       0.73      1.00      0.84        95
           2       0.98      0.91      0.94       111
           3       0.91      0.96      0.93       103
           4       0.93      0.86      0.90        95
           5       0.97      0.90      0.93        97
           6       0.98      0.93      0.96       106
           7       0.87      0.89      0.88        97
           8       0.97      0.90      0.93        87
           9       0.97      0.87      0.92       112

    accuracy                           0.92      1000
   macro avg       0.93      0.92      0.92      1000
weighted avg       0.93      0.92      0.92      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_37x47.txt 3 MA 
Loading data...
Spliting data...
Using n_neighbors=3
Using metric=manhattan
Fitting knn
Predicting...
Accuracy:  0.92
[[ 96   0   0   0   0   1   0   0   0   0]
 [  0  95   0   0   0   0   0   0   0   0]
 [  1   4 101   0   1   0   1   3   0   0]
 [  0   1   0  99   0   1   0   1   1   0]
 [  0  11   2   0  82   0   0   0   0   0]
 [  1   1   0   7   0  87   1   0   0   0]
 [  2   5   0   0   0   0  99   0   0   0]
 [  0   8   0   0   0   0   0  86   0   3]
 [  0   4   0   3   0   1   0   1  78   0]
 [  0   1   0   0   5   0   0   8   1  97]]
              precision    recall  f1-score   support

           0       0.96      0.99      0.97        97
           1       0.73      1.00      0.84        95
           2       0.98      0.91      0.94       111
           3       0.91      0.96      0.93       103
           4       0.93      0.86      0.90        95
           5       0.97      0.90      0.93        97
           6       0.98      0.93      0.96       106
           7       0.87      0.89      0.88        97
           8       0.97      0.90      0.93        87
           9       0.97      0.87      0.92       112

    accuracy                           0.92      1000
   macro avg       0.93      0.92      0.92      1000
weighted avg       0.93      0.92      0.92      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_37x47.txt 3 MI 
Loading data...
Spliting data...
Using n_neighbors=3
Using metric=minkowski
Fitting knn
Predicting...
Accuracy:  0.92
[[ 96   0   0   0   0   1   0   0   0   0]
 [  0  95   0   0   0   0   0   0   0   0]
 [  1   4 101   0   1   0   1   3   0   0]
 [  0   1   0  99   0   1   0   1   1   0]
 [  0  11   2   0  82   0   0   0   0   0]
 [  1   1   0   7   0  87   1   0   0   0]
 [  2   5   0   0   0   0  99   0   0   0]
 [  0   8   0   0   0   0   0  86   0   3]
 [  0   4   0   3   0   1   0   1  78   0]
 [  0   1   0   0   5   0   0   8   1  97]]
              precision    recall  f1-score   support

           0       0.96      0.99      0.97        97
           1       0.73      1.00      0.84        95
           2       0.98      0.91      0.94       111
           3       0.91      0.96      0.93       103
           4       0.93      0.86      0.90        95
           5       0.97      0.90      0.93        97
           6       0.98      0.93      0.96       106
           7       0.87      0.89      0.88        97
           8       0.97      0.90      0.93        87
           9       0.97      0.87      0.92       112

    accuracy                           0.92      1000
   macro avg       0.93      0.92      0.92      1000
weighted avg       0.93      0.92      0.92      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_37x47.txt 5 EU 
Loading data...
Spliting data...
Using n_neighbors=5
Using metric=euclidean
Fitting knn
Predicting...
Accuracy:  0.914
[[ 95   1   0   0   0   1   0   0   0   0]
 [  0  94   0   0   0   0   0   0   0   1]
 [  0   5 101   0   1   0   1   3   0   0]
 [  0   1   0  99   0   1   0   1   1   0]
 [  0  10   1   0  82   0   1   0   0   1]
 [  1   1   0   6   0  88   1   0   0   0]
 [  0   4   0   0   0   0 102   0   0   0]
 [  0   9   0   0   1   0   0  84   0   3]
 [  0   6   0   3   0   1   0   3  74   0]
 [  0   2   0   0   5   0   0  10   0  95]]
              precision    recall  f1-score   support

           0       0.99      0.98      0.98        97
           1       0.71      0.99      0.82        95
           2       0.99      0.91      0.95       111
           3       0.92      0.96      0.94       103
           4       0.92      0.86      0.89        95
           5       0.97      0.91      0.94        97
           6       0.97      0.96      0.97       106
           7       0.83      0.87      0.85        97
           8       0.99      0.85      0.91        87
           9       0.95      0.85      0.90       112

    accuracy                           0.91      1000
   macro avg       0.92      0.91      0.91      1000
weighted avg       0.92      0.91      0.92      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_37x47.txt 5 MA 
Loading data...
Spliting data...
Using n_neighbors=5
Using metric=manhattan
Fitting knn
Predicting...
Accuracy:  0.914
[[ 95   1   0   0   0   1   0   0   0   0]
 [  0  94   0   0   0   0   0   0   0   1]
 [  0   5 101   0   1   0   1   3   0   0]
 [  0   1   0  99   0   1   0   1   1   0]
 [  0  10   1   0  82   0   1   0   0   1]
 [  1   1   0   6   0  88   1   0   0   0]
 [  0   4   0   0   0   0 102   0   0   0]
 [  0   9   0   0   1   0   0  84   0   3]
 [  0   6   0   3   0   1   0   3  74   0]
 [  0   2   0   0   5   0   0  10   0  95]]
              precision    recall  f1-score   support

           0       0.99      0.98      0.98        97
           1       0.71      0.99      0.82        95
           2       0.99      0.91      0.95       111
           3       0.92      0.96      0.94       103
           4       0.92      0.86      0.89        95
           5       0.97      0.91      0.94        97
           6       0.97      0.96      0.97       106
           7       0.83      0.87      0.85        97
           8       0.99      0.85      0.91        87
           9       0.95      0.85      0.90       112

    accuracy                           0.91      1000
   macro avg       0.92      0.91      0.91      1000
weighted avg       0.92      0.91      0.92      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_37x47.txt 5 MI 
Loading data...
Spliting data...
Using n_neighbors=5
Using metric=minkowski
Fitting knn
Predicting...
Accuracy:  0.914
[[ 95   1   0   0   0   1   0   0   0   0]
 [  0  94   0   0   0   0   0   0   0   1]
 [  0   5 101   0   1   0   1   3   0   0]
 [  0   1   0  99   0   1   0   1   1   0]
 [  0  10   1   0  82   0   1   0   0   1]
 [  1   1   0   6   0  88   1   0   0   0]
 [  0   4   0   0   0   0 102   0   0   0]
 [  0   9   0   0   1   0   0  84   0   3]
 [  0   6   0   3   0   1   0   3  74   0]
 [  0   2   0   0   5   0   0  10   0  95]]
              precision    recall  f1-score   support

           0       0.99      0.98      0.98        97
           1       0.71      0.99      0.82        95
           2       0.99      0.91      0.95       111
           3       0.92      0.96      0.94       103
           4       0.92      0.86      0.89        95
           5       0.97      0.91      0.94        97
           6       0.97      0.96      0.97       106
           7       0.83      0.87      0.85        97
           8       0.99      0.85      0.91        87
           9       0.95      0.85      0.90       112

    accuracy                           0.91      1000
   macro avg       0.92      0.91      0.91      1000
weighted avg       0.92      0.91      0.92      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_40x50.txt 1 EU 
Loading data...
Spliting data...
Using n_neighbors=1
Using metric=euclidean
Fitting knn
Predicting...
Accuracy:  0.924
[[ 93   1   0   0   0   1   2   0   0   0]
 [  0  93   0   0   0   1   0   0   0   1]
 [  1   1 102   1   0   0   0   2   2   2]
 [  1   0   0  98   0   1   0   0   3   0]
 [  0   8   0   0  83   1   1   0   0   2]
 [  2   0   0   5   0  89   1   0   0   0]
 [  1   5   0   0   0   0 100   0   0   0]
 [  0   3   1   0   0   0   0  88   0   5]
 [  0   5   0   0   0   3   0   1  78   0]
 [  0   1   0   0   2   0   0   9   0 100]]
              precision    recall  f1-score   support

           0       0.95      0.96      0.95        97
           1       0.79      0.98      0.88        95
           2       0.99      0.92      0.95       111
           3       0.94      0.95      0.95       103
           4       0.98      0.87      0.92        95
           5       0.93      0.92      0.92        97
           6       0.96      0.94      0.95       106
           7       0.88      0.91      0.89        97
           8       0.94      0.90      0.92        87
           9       0.91      0.89      0.90       112

    accuracy                           0.92      1000
   macro avg       0.93      0.92      0.92      1000
weighted avg       0.93      0.92      0.92      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_40x50.txt 1 MA 
Loading data...
Spliting data...
Using n_neighbors=1
Using metric=manhattan
Fitting knn
Predicting...
Accuracy:  0.924
[[ 93   1   0   0   0   1   2   0   0   0]
 [  0  93   0   0   0   1   0   0   0   1]
 [  1   1 102   1   0   0   0   2   2   2]
 [  1   0   0  98   0   1   0   0   3   0]
 [  0   8   0   0  83   1   1   0   0   2]
 [  2   0   0   5   0  89   1   0   0   0]
 [  1   5   0   0   0   0 100   0   0   0]
 [  0   3   1   0   0   0   0  88   0   5]
 [  0   5   0   0   0   3   0   1  78   0]
 [  0   1   0   0   2   0   0   9   0 100]]
              precision    recall  f1-score   support

           0       0.95      0.96      0.95        97
           1       0.79      0.98      0.88        95
           2       0.99      0.92      0.95       111
           3       0.94      0.95      0.95       103
           4       0.98      0.87      0.92        95
           5       0.93      0.92      0.92        97
           6       0.96      0.94      0.95       106
           7       0.88      0.91      0.89        97
           8       0.94      0.90      0.92        87
           9       0.91      0.89      0.90       112

    accuracy                           0.92      1000
   macro avg       0.93      0.92      0.92      1000
weighted avg       0.93      0.92      0.92      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_40x50.txt 1 MI 
Loading data...
Spliting data...
Using n_neighbors=1
Using metric=minkowski
Fitting knn
Predicting...
Accuracy:  0.924
[[ 93   1   0   0   0   1   2   0   0   0]
 [  0  93   0   0   0   1   0   0   0   1]
 [  1   1 102   1   0   0   0   2   2   2]
 [  1   0   0  98   0   1   0   0   3   0]
 [  0   8   0   0  83   1   1   0   0   2]
 [  2   0   0   5   0  89   1   0   0   0]
 [  1   5   0   0   0   0 100   0   0   0]
 [  0   3   1   0   0   0   0  88   0   5]
 [  0   5   0   0   0   3   0   1  78   0]
 [  0   1   0   0   2   0   0   9   0 100]]
              precision    recall  f1-score   support

           0       0.95      0.96      0.95        97
           1       0.79      0.98      0.88        95
           2       0.99      0.92      0.95       111
           3       0.94      0.95      0.95       103
           4       0.98      0.87      0.92        95
           5       0.93      0.92      0.92        97
           6       0.96      0.94      0.95       106
           7       0.88      0.91      0.89        97
           8       0.94      0.90      0.92        87
           9       0.91      0.89      0.90       112

    accuracy                           0.92      1000
   macro avg       0.93      0.92      0.92      1000
weighted avg       0.93      0.92      0.92      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_40x50.txt 3 EU 
Loading data...
Spliting data...
Using n_neighbors=3
Using metric=euclidean
Fitting knn
Predicting...
Accuracy:  0.924
[[ 95   1   0   0   0   1   0   0   0   0]
 [  0  95   0   0   0   0   0   0   0   0]
 [  0   6 101   0   1   0   1   2   0   0]
 [  0   1   0  99   0   1   0   1   1   0]
 [  0  10   2   0  82   0   0   0   0   1]
 [  1   0   0   4   0  91   1   0   0   0]
 [  0   5   0   0   0   0 101   0   0   0]
 [  1   9   0   0   0   0   0  85   0   2]
 [  0   5   0   3   0   1   0   1  76   1]
 [  0   1   0   0   4   0   0   7   1  99]]
              precision    recall  f1-score   support

           0       0.98      0.98      0.98        97
           1       0.71      1.00      0.83        95
           2       0.98      0.91      0.94       111
           3       0.93      0.96      0.95       103
           4       0.94      0.86      0.90        95
           5       0.97      0.94      0.95        97
           6       0.98      0.95      0.97       106
           7       0.89      0.88      0.88        97
           8       0.97      0.87      0.92        87
           9       0.96      0.88      0.92       112

    accuracy                           0.92      1000
   macro avg       0.93      0.92      0.92      1000
weighted avg       0.93      0.92      0.93      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_40x50.txt 3 MA 
Loading data...
Spliting data...
Using n_neighbors=3
Using metric=manhattan
Fitting knn
Predicting...
Accuracy:  0.924
[[ 95   1   0   0   0   1   0   0   0   0]
 [  0  95   0   0   0   0   0   0   0   0]
 [  0   6 101   0   1   0   1   2   0   0]
 [  0   1   0  99   0   1   0   1   1   0]
 [  0  10   2   0  82   0   0   0   0   1]
 [  1   0   0   4   0  91   1   0   0   0]
 [  0   5   0   0   0   0 101   0   0   0]
 [  1   9   0   0   0   0   0  85   0   2]
 [  0   5   0   3   0   1   0   1  76   1]
 [  0   1   0   0   4   0   0   7   1  99]]
              precision    recall  f1-score   support

           0       0.98      0.98      0.98        97
           1       0.71      1.00      0.83        95
           2       0.98      0.91      0.94       111
           3       0.93      0.96      0.95       103
           4       0.94      0.86      0.90        95
           5       0.97      0.94      0.95        97
           6       0.98      0.95      0.97       106
           7       0.89      0.88      0.88        97
           8       0.97      0.87      0.92        87
           9       0.96      0.88      0.92       112

    accuracy                           0.92      1000
   macro avg       0.93      0.92      0.92      1000
weighted avg       0.93      0.92      0.93      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_40x50.txt 3 MI 
Loading data...
Spliting data...
Using n_neighbors=3
Using metric=minkowski
Fitting knn
Predicting...
Accuracy:  0.924
[[ 95   1   0   0   0   1   0   0   0   0]
 [  0  95   0   0   0   0   0   0   0   0]
 [  0   6 101   0   1   0   1   2   0   0]
 [  0   1   0  99   0   1   0   1   1   0]
 [  0  10   2   0  82   0   0   0   0   1]
 [  1   0   0   4   0  91   1   0   0   0]
 [  0   5   0   0   0   0 101   0   0   0]
 [  1   9   0   0   0   0   0  85   0   2]
 [  0   5   0   3   0   1   0   1  76   1]
 [  0   1   0   0   4   0   0   7   1  99]]
              precision    recall  f1-score   support

           0       0.98      0.98      0.98        97
           1       0.71      1.00      0.83        95
           2       0.98      0.91      0.94       111
           3       0.93      0.96      0.95       103
           4       0.94      0.86      0.90        95
           5       0.97      0.94      0.95        97
           6       0.98      0.95      0.97       106
           7       0.89      0.88      0.88        97
           8       0.97      0.87      0.92        87
           9       0.96      0.88      0.92       112

    accuracy                           0.92      1000
   macro avg       0.93      0.92      0.92      1000
weighted avg       0.93      0.92      0.93      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_40x50.txt 5 EU 
Loading data...
Spliting data...
Using n_neighbors=5
Using metric=euclidean
Fitting knn
Predicting...
Accuracy:  0.906
[[ 95   1   0   0   0   1   0   0   0   0]
 [  0  94   0   0   0   0   0   0   0   1]
 [  1   6  99   0   2   0   1   2   0   0]
 [  0   1   0  96   0   1   0   2   3   0]
 [  0  12   1   0  82   0   0   0   0   0]
 [  1   1   0   6   0  88   1   0   0   0]
 [  0   6   0   0   0   0 100   0   0   0]
 [  0   9   0   0   1   0   0  84   0   3]
 [  0   6   0   3   0   1   0   3  73   1]
 [  0   2   0   0   5   0   0  10   0  95]]
              precision    recall  f1-score   support

           0       0.98      0.98      0.98        97
           1       0.68      0.99      0.81        95
           2       0.99      0.89      0.94       111
           3       0.91      0.93      0.92       103
           4       0.91      0.86      0.89        95
           5       0.97      0.91      0.94        97
           6       0.98      0.94      0.96       106
           7       0.83      0.87      0.85        97
           8       0.96      0.84      0.90        87
           9       0.95      0.85      0.90       112

    accuracy                           0.91      1000
   macro avg       0.92      0.91      0.91      1000
weighted avg       0.92      0.91      0.91      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_40x50.txt 5 MA 
Loading data...
Spliting data...
Using n_neighbors=5
Using metric=manhattan
Fitting knn
Predicting...
Accuracy:  0.906
[[ 95   1   0   0   0   1   0   0   0   0]
 [  0  94   0   0   0   0   0   0   0   1]
 [  1   6  99   0   2   0   1   2   0   0]
 [  0   1   0  96   0   1   0   2   3   0]
 [  0  12   1   0  82   0   0   0   0   0]
 [  1   1   0   6   0  88   1   0   0   0]
 [  0   6   0   0   0   0 100   0   0   0]
 [  0   9   0   0   1   0   0  84   0   3]
 [  0   6   0   3   0   1   0   3  73   1]
 [  0   2   0   0   5   0   0  10   0  95]]
              precision    recall  f1-score   support

           0       0.98      0.98      0.98        97
           1       0.68      0.99      0.81        95
           2       0.99      0.89      0.94       111
           3       0.91      0.93      0.92       103
           4       0.91      0.86      0.89        95
           5       0.97      0.91      0.94        97
           6       0.98      0.94      0.96       106
           7       0.83      0.87      0.85        97
           8       0.96      0.84      0.90        87
           9       0.95      0.85      0.90       112

    accuracy                           0.91      1000
   macro avg       0.92      0.91      0.91      1000
weighted avg       0.92      0.91      0.91      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_40x50.txt 5 MI 
Loading data...
Spliting data...
Using n_neighbors=5
Using metric=minkowski
Fitting knn
Predicting...
Accuracy:  0.906
[[ 95   1   0   0   0   1   0   0   0   0]
 [  0  94   0   0   0   0   0   0   0   1]
 [  1   6  99   0   2   0   1   2   0   0]
 [  0   1   0  96   0   1   0   2   3   0]
 [  0  12   1   0  82   0   0   0   0   0]
 [  1   1   0   6   0  88   1   0   0   0]
 [  0   6   0   0   0   0 100   0   0   0]
 [  0   9   0   0   1   0   0  84   0   3]
 [  0   6   0   3   0   1   0   3  73   1]
 [  0   2   0   0   5   0   0  10   0  95]]
              precision    recall  f1-score   support

           0       0.98      0.98      0.98        97
           1       0.68      0.99      0.81        95
           2       0.99      0.89      0.94       111
           3       0.91      0.93      0.92       103
           4       0.91      0.86      0.89        95
           5       0.97      0.91      0.94        97
           6       0.98      0.94      0.96       106
           7       0.83      0.87      0.85        97
           8       0.96      0.84      0.90        87
           9       0.95      0.85      0.90       112

    accuracy                           0.91      1000
   macro avg       0.92      0.91      0.91      1000
weighted avg       0.92      0.91      0.91      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_50x60.txt 1 EU 
Loading data...
Spliting data...
Using n_neighbors=1
Using metric=euclidean
Fitting knn
Predicting...
Accuracy:  0.93
[[ 94   1   0   0   0   1   1   0   0   0]
 [  0  93   0   0   0   1   0   0   0   1]
 [  1   2 102   1   0   0   0   3   1   1]
 [  0   1   0  98   0   1   0   0   3   0]
 [  0   8   0   0  84   1   1   0   0   1]
 [  1   0   0   6   0  89   1   0   0   0]
 [  1   5   0   0   0   0 100   0   0   0]
 [  0   3   1   0   0   0   0  90   0   3]
 [  0   3   0   1   1   2   0   1  79   0]
 [  0   1   0   0   1   0   0   9   0 101]]
              precision    recall  f1-score   support

           0       0.97      0.97      0.97        97
           1       0.79      0.98      0.88        95
           2       0.99      0.92      0.95       111
           3       0.92      0.95      0.94       103
           4       0.98      0.88      0.93        95
           5       0.94      0.92      0.93        97
           6       0.97      0.94      0.96       106
           7       0.87      0.93      0.90        97
           8       0.95      0.91      0.93        87
           9       0.94      0.90      0.92       112

    accuracy                           0.93      1000
   macro avg       0.93      0.93      0.93      1000
weighted avg       0.93      0.93      0.93      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_50x60.txt 1 MA 
Loading data...
Spliting data...
Using n_neighbors=1
Using metric=manhattan
Fitting knn
Predicting...
Accuracy:  0.93
[[ 94   1   0   0   0   1   1   0   0   0]
 [  0  93   0   0   0   1   0   0   0   1]
 [  1   2 102   1   0   0   0   3   1   1]
 [  0   1   0  98   0   1   0   0   3   0]
 [  0   8   0   0  84   1   1   0   0   1]
 [  1   0   0   6   0  89   1   0   0   0]
 [  1   5   0   0   0   0 100   0   0   0]
 [  0   3   1   0   0   0   0  90   0   3]
 [  0   3   0   1   1   2   0   1  79   0]
 [  0   1   0   0   1   0   0   9   0 101]]
              precision    recall  f1-score   support

           0       0.97      0.97      0.97        97
           1       0.79      0.98      0.88        95
           2       0.99      0.92      0.95       111
           3       0.92      0.95      0.94       103
           4       0.98      0.88      0.93        95
           5       0.94      0.92      0.93        97
           6       0.97      0.94      0.96       106
           7       0.87      0.93      0.90        97
           8       0.95      0.91      0.93        87
           9       0.94      0.90      0.92       112

    accuracy                           0.93      1000
   macro avg       0.93      0.93      0.93      1000
weighted avg       0.93      0.93      0.93      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_50x60.txt 1 MI 
Loading data...
Spliting data...
Using n_neighbors=1
Using metric=minkowski
Fitting knn
Predicting...
Accuracy:  0.93
[[ 94   1   0   0   0   1   1   0   0   0]
 [  0  93   0   0   0   1   0   0   0   1]
 [  1   2 102   1   0   0   0   3   1   1]
 [  0   1   0  98   0   1   0   0   3   0]
 [  0   8   0   0  84   1   1   0   0   1]
 [  1   0   0   6   0  89   1   0   0   0]
 [  1   5   0   0   0   0 100   0   0   0]
 [  0   3   1   0   0   0   0  90   0   3]
 [  0   3   0   1   1   2   0   1  79   0]
 [  0   1   0   0   1   0   0   9   0 101]]
              precision    recall  f1-score   support

           0       0.97      0.97      0.97        97
           1       0.79      0.98      0.88        95
           2       0.99      0.92      0.95       111
           3       0.92      0.95      0.94       103
           4       0.98      0.88      0.93        95
           5       0.94      0.92      0.93        97
           6       0.97      0.94      0.96       106
           7       0.87      0.93      0.90        97
           8       0.95      0.91      0.93        87
           9       0.94      0.90      0.92       112

    accuracy                           0.93      1000
   macro avg       0.93      0.93      0.93      1000
weighted avg       0.93      0.93      0.93      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_50x60.txt 3 EU 
Loading data...
Spliting data...
Using n_neighbors=3
Using metric=euclidean
Fitting knn
Predicting...
Accuracy:  0.919
[[ 96   0   0   0   0   1   0   0   0   0]
 [  0  95   0   0   0   0   0   0   0   0]
 [  0   6 100   0   1   0   1   2   1   0]
 [  0   1   0  99   0   1   0   0   2   0]
 [  0  10   2   0  82   0   0   0   0   1]
 [  1   0   0   4   0  91   1   0   0   0]
 [  1   6   0   0   0   0  99   0   0   0]
 [  1   9   0   0   0   0   0  84   0   3]
 [  0   4   0   3   0   1   0   1  76   2]
 [  0   1   0   0   5   0   0   8   1  97]]
              precision    recall  f1-score   support

           0       0.97      0.99      0.98        97
           1       0.72      1.00      0.84        95
           2       0.98      0.90      0.94       111
           3       0.93      0.96      0.95       103
           4       0.93      0.86      0.90        95
           5       0.97      0.94      0.95        97
           6       0.98      0.93      0.96       106
           7       0.88      0.87      0.87        97
           8       0.95      0.87      0.91        87
           9       0.94      0.87      0.90       112

    accuracy                           0.92      1000
   macro avg       0.93      0.92      0.92      1000
weighted avg       0.93      0.92      0.92      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_50x60.txt 3 MA 
Loading data...
Spliting data...
Using n_neighbors=3
Using metric=manhattan
Fitting knn
Predicting...
Accuracy:  0.919
[[ 96   0   0   0   0   1   0   0   0   0]
 [  0  95   0   0   0   0   0   0   0   0]
 [  0   6 100   0   1   0   1   2   1   0]
 [  0   1   0  99   0   1   0   0   2   0]
 [  0  10   2   0  82   0   0   0   0   1]
 [  1   0   0   4   0  91   1   0   0   0]
 [  1   6   0   0   0   0  99   0   0   0]
 [  1   9   0   0   0   0   0  84   0   3]
 [  0   4   0   3   0   1   0   1  76   2]
 [  0   1   0   0   5   0   0   8   1  97]]
              precision    recall  f1-score   support

           0       0.97      0.99      0.98        97
           1       0.72      1.00      0.84        95
           2       0.98      0.90      0.94       111
           3       0.93      0.96      0.95       103
           4       0.93      0.86      0.90        95
           5       0.97      0.94      0.95        97
           6       0.98      0.93      0.96       106
           7       0.88      0.87      0.87        97
           8       0.95      0.87      0.91        87
           9       0.94      0.87      0.90       112

    accuracy                           0.92      1000
   macro avg       0.93      0.92      0.92      1000
weighted avg       0.93      0.92      0.92      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_50x60.txt 3 MI 
Loading data...
Spliting data...
Using n_neighbors=3
Using metric=minkowski
Fitting knn
Predicting...
Accuracy:  0.919
[[ 96   0   0   0   0   1   0   0   0   0]
 [  0  95   0   0   0   0   0   0   0   0]
 [  0   6 100   0   1   0   1   2   1   0]
 [  0   1   0  99   0   1   0   0   2   0]
 [  0  10   2   0  82   0   0   0   0   1]
 [  1   0   0   4   0  91   1   0   0   0]
 [  1   6   0   0   0   0  99   0   0   0]
 [  1   9   0   0   0   0   0  84   0   3]
 [  0   4   0   3   0   1   0   1  76   2]
 [  0   1   0   0   5   0   0   8   1  97]]
              precision    recall  f1-score   support

           0       0.97      0.99      0.98        97
           1       0.72      1.00      0.84        95
           2       0.98      0.90      0.94       111
           3       0.93      0.96      0.95       103
           4       0.93      0.86      0.90        95
           5       0.97      0.94      0.95        97
           6       0.98      0.93      0.96       106
           7       0.88      0.87      0.87        97
           8       0.95      0.87      0.91        87
           9       0.94      0.87      0.90       112

    accuracy                           0.92      1000
   macro avg       0.93      0.92      0.92      1000
weighted avg       0.93      0.92      0.92      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_50x60.txt 5 EU 
Loading data...
Spliting data...
Using n_neighbors=5
Using metric=euclidean
Fitting knn
Predicting...
Accuracy:  0.916
[[ 95   1   0   0   0   1   0   0   0   0]
 [  0  94   0   0   0   0   0   0   0   1]
 [  0   6 101   0   1   0   1   2   0   0]
 [  0   1   0  98   0   1   0   1   2   0]
 [  0  11   1   0  83   0   0   0   0   0]
 [  1   1   0   6   0  88   1   0   0   0]
 [  0   6   0   0   0   0 100   0   0   0]
 [  0   8   0   0   0   0   0  86   0   3]
 [  0   4   0   4   1   2   0   2  74   0]
 [  0   2   0   0   4   0   0   9   0  97]]
              precision    recall  f1-score   support

           0       0.99      0.98      0.98        97
           1       0.70      0.99      0.82        95
           2       0.99      0.91      0.95       111
           3       0.91      0.95      0.93       103
           4       0.93      0.87      0.90        95
           5       0.96      0.91      0.93        97
           6       0.98      0.94      0.96       106
           7       0.86      0.89      0.87        97
           8       0.97      0.85      0.91        87
           9       0.96      0.87      0.91       112

    accuracy                           0.92      1000
   macro avg       0.93      0.92      0.92      1000
weighted avg       0.93      0.92      0.92      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_50x60.txt 5 MA 
Loading data...
Spliting data...
Using n_neighbors=5
Using metric=manhattan
Fitting knn
Predicting...
Accuracy:  0.916
[[ 95   1   0   0   0   1   0   0   0   0]
 [  0  94   0   0   0   0   0   0   0   1]
 [  0   6 101   0   1   0   1   2   0   0]
 [  0   1   0  98   0   1   0   1   2   0]
 [  0  11   1   0  83   0   0   0   0   0]
 [  1   1   0   6   0  88   1   0   0   0]
 [  0   6   0   0   0   0 100   0   0   0]
 [  0   8   0   0   0   0   0  86   0   3]
 [  0   4   0   4   1   2   0   2  74   0]
 [  0   2   0   0   4   0   0   9   0  97]]
              precision    recall  f1-score   support

           0       0.99      0.98      0.98        97
           1       0.70      0.99      0.82        95
           2       0.99      0.91      0.95       111
           3       0.91      0.95      0.93       103
           4       0.93      0.87      0.90        95
           5       0.96      0.91      0.93        97
           6       0.98      0.94      0.96       106
           7       0.86      0.89      0.87        97
           8       0.97      0.85      0.91        87
           9       0.96      0.87      0.91       112

    accuracy                           0.92      1000
   macro avg       0.93      0.92      0.92      1000
weighted avg       0.93      0.92      0.92      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_50x60.txt 5 MI 
Loading data...
Spliting data...
Using n_neighbors=5
Using metric=minkowski
Fitting knn
Predicting...
Accuracy:  0.916
[[ 95   1   0   0   0   1   0   0   0   0]
 [  0  94   0   0   0   0   0   0   0   1]
 [  0   6 101   0   1   0   1   2   0   0]
 [  0   1   0  98   0   1   0   1   2   0]
 [  0  11   1   0  83   0   0   0   0   0]
 [  1   1   0   6   0  88   1   0   0   0]
 [  0   6   0   0   0   0 100   0   0   0]
 [  0   8   0   0   0   0   0  86   0   3]
 [  0   4   0   4   1   2   0   2  74   0]
 [  0   2   0   0   4   0   0   9   0  97]]
              precision    recall  f1-score   support

           0       0.99      0.98      0.98        97
           1       0.70      0.99      0.82        95
           2       0.99      0.91      0.95       111
           3       0.91      0.95      0.93       103
           4       0.93      0.87      0.90        95
           5       0.96      0.91      0.93        97
           6       0.98      0.94      0.96       106
           7       0.86      0.89      0.87        97
           8       0.97      0.85      0.91        87
           9       0.96      0.87      0.91       112

    accuracy                           0.92      1000
   macro avg       0.93      0.92      0.92      1000
weighted avg       0.93      0.92      0.92      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_60x30.txt 1 EU 
Loading data...
Spliting data...
Using n_neighbors=1
Using metric=euclidean
Fitting knn
Predicting...
Accuracy:  0.925
[[ 95   1   0   0   0   1   0   0   0   0]
 [  0  93   0   0   0   1   0   1   0   0]
 [  1   2 101   1   0   0   0   5   0   1]
 [  0   1   0  99   0   1   0   0   2   0]
 [  0   8   0   0  83   0   1   0   0   3]
 [  1   1   0   6   0  88   1   0   0   0]
 [  2   5   0   0   0   0  99   0   0   0]
 [  0   3   1   0   1   0   0  87   0   5]
 [  0   2   0   0   1   3   0   1  80   0]
 [  0   1   0   0   1   0   0  10   0 100]]
              precision    recall  f1-score   support

           0       0.96      0.98      0.97        97
           1       0.79      0.98      0.88        95
           2       0.99      0.91      0.95       111
           3       0.93      0.96      0.95       103
           4       0.97      0.87      0.92        95
           5       0.94      0.91      0.92        97
           6       0.98      0.93      0.96       106
           7       0.84      0.90      0.87        97
           8       0.98      0.92      0.95        87
           9       0.92      0.89      0.90       112

    accuracy                           0.93      1000
   macro avg       0.93      0.93      0.93      1000
weighted avg       0.93      0.93      0.93      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_60x30.txt 1 MA 
Loading data...
Spliting data...
Using n_neighbors=1
Using metric=manhattan
Fitting knn
Predicting...
Accuracy:  0.925
[[ 95   1   0   0   0   1   0   0   0   0]
 [  0  93   0   0   0   1   0   1   0   0]
 [  1   2 101   1   0   0   0   5   0   1]
 [  0   1   0  99   0   1   0   0   2   0]
 [  0   8   0   0  83   0   1   0   0   3]
 [  1   1   0   6   0  88   1   0   0   0]
 [  2   5   0   0   0   0  99   0   0   0]
 [  0   3   1   0   1   0   0  87   0   5]
 [  0   2   0   0   1   3   0   1  80   0]
 [  0   1   0   0   1   0   0  10   0 100]]
              precision    recall  f1-score   support

           0       0.96      0.98      0.97        97
           1       0.79      0.98      0.88        95
           2       0.99      0.91      0.95       111
           3       0.93      0.96      0.95       103
           4       0.97      0.87      0.92        95
           5       0.94      0.91      0.92        97
           6       0.98      0.93      0.96       106
           7       0.84      0.90      0.87        97
           8       0.98      0.92      0.95        87
           9       0.92      0.89      0.90       112

    accuracy                           0.93      1000
   macro avg       0.93      0.93      0.93      1000
weighted avg       0.93      0.93      0.93      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_60x30.txt 1 MI 
Loading data...
Spliting data...
Using n_neighbors=1
Using metric=minkowski
Fitting knn
Predicting...
Accuracy:  0.925
[[ 95   1   0   0   0   1   0   0   0   0]
 [  0  93   0   0   0   1   0   1   0   0]
 [  1   2 101   1   0   0   0   5   0   1]
 [  0   1   0  99   0   1   0   0   2   0]
 [  0   8   0   0  83   0   1   0   0   3]
 [  1   1   0   6   0  88   1   0   0   0]
 [  2   5   0   0   0   0  99   0   0   0]
 [  0   3   1   0   1   0   0  87   0   5]
 [  0   2   0   0   1   3   0   1  80   0]
 [  0   1   0   0   1   0   0  10   0 100]]
              precision    recall  f1-score   support

           0       0.96      0.98      0.97        97
           1       0.79      0.98      0.88        95
           2       0.99      0.91      0.95       111
           3       0.93      0.96      0.95       103
           4       0.97      0.87      0.92        95
           5       0.94      0.91      0.92        97
           6       0.98      0.93      0.96       106
           7       0.84      0.90      0.87        97
           8       0.98      0.92      0.95        87
           9       0.92      0.89      0.90       112

    accuracy                           0.93      1000
   macro avg       0.93      0.93      0.93      1000
weighted avg       0.93      0.93      0.93      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_60x30.txt 3 EU 
Loading data...
Spliting data...
Using n_neighbors=3
Using metric=euclidean
Fitting knn
Predicting...
Accuracy:  0.918
[[ 94   2   0   0   0   1   0   0   0   0]
 [  0  95   0   0   0   0   0   0   0   0]
 [  0   6 100   0   1   0   1   3   0   0]
 [  1   1   1  97   0   1   0   1   1   0]
 [  0  10   2   0  81   0   0   0   0   2]
 [  1   1   0   4   0  90   1   0   0   0]
 [  0   6   0   0   1   0  99   0   0   0]
 [  1   8   0   0   0   0   0  85   0   3]
 [  1   3   0   3   0   1   0   0  78   1]
 [  0   1   0   0   3   0   0   8   1  99]]
              precision    recall  f1-score   support

           0       0.96      0.97      0.96        97
           1       0.71      1.00      0.83        95
           2       0.97      0.90      0.93       111
           3       0.93      0.94      0.94       103
           4       0.94      0.85      0.90        95
           5       0.97      0.93      0.95        97
           6       0.98      0.93      0.96       106
           7       0.88      0.88      0.88        97
           8       0.97      0.90      0.93        87
           9       0.94      0.88      0.91       112

    accuracy                           0.92      1000
   macro avg       0.93      0.92      0.92      1000
weighted avg       0.93      0.92      0.92      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_60x30.txt 3 MA 
Loading data...
Spliting data...
Using n_neighbors=3
Using metric=manhattan
Fitting knn
Predicting...
Accuracy:  0.918
[[ 94   2   0   0   0   1   0   0   0   0]
 [  0  95   0   0   0   0   0   0   0   0]
 [  0   6 100   0   1   0   1   3   0   0]
 [  1   1   1  97   0   1   0   1   1   0]
 [  0  10   2   0  81   0   0   0   0   2]
 [  1   1   0   4   0  90   1   0   0   0]
 [  0   6   0   0   1   0  99   0   0   0]
 [  1   8   0   0   0   0   0  85   0   3]
 [  1   3   0   3   0   1   0   0  78   1]
 [  0   1   0   0   3   0   0   8   1  99]]
              precision    recall  f1-score   support

           0       0.96      0.97      0.96        97
           1       0.71      1.00      0.83        95
           2       0.97      0.90      0.93       111
           3       0.93      0.94      0.94       103
           4       0.94      0.85      0.90        95
           5       0.97      0.93      0.95        97
           6       0.98      0.93      0.96       106
           7       0.88      0.88      0.88        97
           8       0.97      0.90      0.93        87
           9       0.94      0.88      0.91       112

    accuracy                           0.92      1000
   macro avg       0.93      0.92      0.92      1000
weighted avg       0.93      0.92      0.92      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_60x30.txt 3 MI 
Loading data...
Spliting data...
Using n_neighbors=3
Using metric=minkowski
Fitting knn
Predicting...
Accuracy:  0.918
[[ 94   2   0   0   0   1   0   0   0   0]
 [  0  95   0   0   0   0   0   0   0   0]
 [  0   6 100   0   1   0   1   3   0   0]
 [  1   1   1  97   0   1   0   1   1   0]
 [  0  10   2   0  81   0   0   0   0   2]
 [  1   1   0   4   0  90   1   0   0   0]
 [  0   6   0   0   1   0  99   0   0   0]
 [  1   8   0   0   0   0   0  85   0   3]
 [  1   3   0   3   0   1   0   0  78   1]
 [  0   1   0   0   3   0   0   8   1  99]]
              precision    recall  f1-score   support

           0       0.96      0.97      0.96        97
           1       0.71      1.00      0.83        95
           2       0.97      0.90      0.93       111
           3       0.93      0.94      0.94       103
           4       0.94      0.85      0.90        95
           5       0.97      0.93      0.95        97
           6       0.98      0.93      0.96       106
           7       0.88      0.88      0.88        97
           8       0.97      0.90      0.93        87
           9       0.94      0.88      0.91       112

    accuracy                           0.92      1000
   macro avg       0.93      0.92      0.92      1000
weighted avg       0.93      0.92      0.92      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_60x30.txt 5 EU 
Loading data...
Spliting data...
Using n_neighbors=5
Using metric=euclidean
Fitting knn
Predicting...
Accuracy:  0.914
[[ 94   2   0   0   0   1   0   0   0   0]
 [  0  94   0   0   0   0   0   0   0   1]
 [  0   6 100   0   1   0   1   3   0   0]
 [  0   1   0  99   0   0   0   2   1   0]
 [  0  11   1   0  83   0   0   0   0   0]
 [  1   1   0   6   0  88   1   0   0   0]
 [  0   6   0   0   0   0 100   0   0   0]
 [  0   8   0   0   1   0   0  86   0   2]
 [  0   3   0   2   1   2   0   3  75   1]
 [  0   2   0   0   4   0   0  11   0  95]]
              precision    recall  f1-score   support

           0       0.99      0.97      0.98        97
           1       0.70      0.99      0.82        95
           2       0.99      0.90      0.94       111
           3       0.93      0.96      0.94       103
           4       0.92      0.87      0.90        95
           5       0.97      0.91      0.94        97
           6       0.98      0.94      0.96       106
           7       0.82      0.89      0.85        97
           8       0.99      0.86      0.92        87
           9       0.96      0.85      0.90       112

    accuracy                           0.91      1000
   macro avg       0.92      0.91      0.92      1000
weighted avg       0.93      0.91      0.92      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_60x30.txt 5 MA 
Loading data...
Spliting data...
Using n_neighbors=5
Using metric=manhattan
Fitting knn
Predicting...
Accuracy:  0.914
[[ 94   2   0   0   0   1   0   0   0   0]
 [  0  94   0   0   0   0   0   0   0   1]
 [  0   6 100   0   1   0   1   3   0   0]
 [  0   1   0  99   0   0   0   2   1   0]
 [  0  11   1   0  83   0   0   0   0   0]
 [  1   1   0   6   0  88   1   0   0   0]
 [  0   6   0   0   0   0 100   0   0   0]
 [  0   8   0   0   1   0   0  86   0   2]
 [  0   3   0   2   1   2   0   3  75   1]
 [  0   2   0   0   4   0   0  11   0  95]]
              precision    recall  f1-score   support

           0       0.99      0.97      0.98        97
           1       0.70      0.99      0.82        95
           2       0.99      0.90      0.94       111
           3       0.93      0.96      0.94       103
           4       0.92      0.87      0.90        95
           5       0.97      0.91      0.94        97
           6       0.98      0.94      0.96       106
           7       0.82      0.89      0.85        97
           8       0.99      0.86      0.92        87
           9       0.96      0.85      0.90       112

    accuracy                           0.91      1000
   macro avg       0.92      0.91      0.92      1000
weighted avg       0.93      0.91      0.92      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_60x30.txt 5 MI 
Loading data...
Spliting data...
Using n_neighbors=5
Using metric=minkowski
Fitting knn
Predicting...
Accuracy:  0.914
[[ 94   2   0   0   0   1   0   0   0   0]
 [  0  94   0   0   0   0   0   0   0   1]
 [  0   6 100   0   1   0   1   3   0   0]
 [  0   1   0  99   0   0   0   2   1   0]
 [  0  11   1   0  83   0   0   0   0   0]
 [  1   1   0   6   0  88   1   0   0   0]
 [  0   6   0   0   0   0 100   0   0   0]
 [  0   8   0   0   1   0   0  86   0   2]
 [  0   3   0   2   1   2   0   3  75   1]
 [  0   2   0   0   4   0   0  11   0  95]]
              precision    recall  f1-score   support

           0       0.99      0.97      0.98        97
           1       0.70      0.99      0.82        95
           2       0.99      0.90      0.94       111
           3       0.93      0.96      0.94       103
           4       0.92      0.87      0.90        95
           5       0.97      0.91      0.94        97
           6       0.98      0.94      0.96       106
           7       0.82      0.89      0.85        97
           8       0.99      0.86      0.92        87
           9       0.96      0.85      0.90       112

    accuracy                           0.91      1000
   macro avg       0.92      0.91      0.92      1000
weighted avg       0.93      0.91      0.92      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_60x70.txt 1 EU 
Loading data...
Spliting data...
Using n_neighbors=1
Using metric=euclidean
Fitting knn
Predicting...
Accuracy:  0.926
[[ 95   1   0   0   0   1   0   0   0   0]
 [  0  93   0   0   0   1   0   0   0   1]
 [  1   1 102   1   0   0   0   4   1   1]
 [  0   1   0  98   0   1   0   0   3   0]
 [  0   8   0   0  82   1   1   0   0   3]
 [  2   0   0   5   0  89   1   0   0   0]
 [  1   5   0   0   0   0 100   0   0   0]
 [  0   3   1   0   1   0   0  88   0   4]
 [  0   4   0   1   0   2   0   1  79   0]
 [  0   1   0   0   1   0   0  10   0 100]]
              precision    recall  f1-score   support

           0       0.96      0.98      0.97        97
           1       0.79      0.98      0.88        95
           2       0.99      0.92      0.95       111
           3       0.93      0.95      0.94       103
           4       0.98      0.86      0.92        95
           5       0.94      0.92      0.93        97
           6       0.98      0.94      0.96       106
           7       0.85      0.91      0.88        97
           8       0.95      0.91      0.93        87
           9       0.92      0.89      0.90       112

    accuracy                           0.93      1000
   macro avg       0.93      0.93      0.93      1000
weighted avg       0.93      0.93      0.93      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_60x70.txt 1 MA 
Loading data...
Spliting data...
Using n_neighbors=1
Using metric=manhattan
Fitting knn
Predicting...
Accuracy:  0.926
[[ 95   1   0   0   0   1   0   0   0   0]
 [  0  93   0   0   0   1   0   0   0   1]
 [  1   1 102   1   0   0   0   4   1   1]
 [  0   1   0  98   0   1   0   0   3   0]
 [  0   8   0   0  82   1   1   0   0   3]
 [  2   0   0   5   0  89   1   0   0   0]
 [  1   5   0   0   0   0 100   0   0   0]
 [  0   3   1   0   1   0   0  88   0   4]
 [  0   4   0   1   0   2   0   1  79   0]
 [  0   1   0   0   1   0   0  10   0 100]]
              precision    recall  f1-score   support

           0       0.96      0.98      0.97        97
           1       0.79      0.98      0.88        95
           2       0.99      0.92      0.95       111
           3       0.93      0.95      0.94       103
           4       0.98      0.86      0.92        95
           5       0.94      0.92      0.93        97
           6       0.98      0.94      0.96       106
           7       0.85      0.91      0.88        97
           8       0.95      0.91      0.93        87
           9       0.92      0.89      0.90       112

    accuracy                           0.93      1000
   macro avg       0.93      0.93      0.93      1000
weighted avg       0.93      0.93      0.93      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_60x70.txt 1 MI 
Loading data...
Spliting data...
Using n_neighbors=1
Using metric=minkowski
Fitting knn
Predicting...
Accuracy:  0.926
[[ 95   1   0   0   0   1   0   0   0   0]
 [  0  93   0   0   0   1   0   0   0   1]
 [  1   1 102   1   0   0   0   4   1   1]
 [  0   1   0  98   0   1   0   0   3   0]
 [  0   8   0   0  82   1   1   0   0   3]
 [  2   0   0   5   0  89   1   0   0   0]
 [  1   5   0   0   0   0 100   0   0   0]
 [  0   3   1   0   1   0   0  88   0   4]
 [  0   4   0   1   0   2   0   1  79   0]
 [  0   1   0   0   1   0   0  10   0 100]]
              precision    recall  f1-score   support

           0       0.96      0.98      0.97        97
           1       0.79      0.98      0.88        95
           2       0.99      0.92      0.95       111
           3       0.93      0.95      0.94       103
           4       0.98      0.86      0.92        95
           5       0.94      0.92      0.93        97
           6       0.98      0.94      0.96       106
           7       0.85      0.91      0.88        97
           8       0.95      0.91      0.93        87
           9       0.92      0.89      0.90       112

    accuracy                           0.93      1000
   macro avg       0.93      0.93      0.93      1000
weighted avg       0.93      0.93      0.93      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_60x70.txt 3 EU 
Loading data...
Spliting data...
Using n_neighbors=3
Using metric=euclidean
Fitting knn
Predicting...
Accuracy:  0.924
[[ 96   0   0   0   0   1   0   0   0   0]
 [  0  95   0   0   0   0   0   0   0   0]
 [  0   4 102   0   1   0   1   2   1   0]
 [  0   1   0  98   0   1   0   1   2   0]
 [  0  10   2   0  82   0   0   0   0   1]
 [  1   0   0   4   0  91   1   0   0   0]
 [  2   5   0   0   0   0  99   0   0   0]
 [  1   8   0   0   0   0   0  85   0   3]
 [  1   3   0   3   0   1   0   0  77   2]
 [  0   1   0   0   3   0   0   8   1  99]]
              precision    recall  f1-score   support

           0       0.95      0.99      0.97        97
           1       0.75      1.00      0.86        95
           2       0.98      0.92      0.95       111
           3       0.93      0.95      0.94       103
           4       0.95      0.86      0.91        95
           5       0.97      0.94      0.95        97
           6       0.98      0.93      0.96       106
           7       0.89      0.88      0.88        97
           8       0.95      0.89      0.92        87
           9       0.94      0.88      0.91       112

    accuracy                           0.92      1000
   macro avg       0.93      0.92      0.92      1000
weighted avg       0.93      0.92      0.93      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_60x70.txt 3 MA 
Loading data...
Spliting data...
Using n_neighbors=3
Using metric=manhattan
Fitting knn
Predicting...
Accuracy:  0.924
[[ 96   0   0   0   0   1   0   0   0   0]
 [  0  95   0   0   0   0   0   0   0   0]
 [  0   4 102   0   1   0   1   2   1   0]
 [  0   1   0  98   0   1   0   1   2   0]
 [  0  10   2   0  82   0   0   0   0   1]
 [  1   0   0   4   0  91   1   0   0   0]
 [  2   5   0   0   0   0  99   0   0   0]
 [  1   8   0   0   0   0   0  85   0   3]
 [  1   3   0   3   0   1   0   0  77   2]
 [  0   1   0   0   3   0   0   8   1  99]]
              precision    recall  f1-score   support

           0       0.95      0.99      0.97        97
           1       0.75      1.00      0.86        95
           2       0.98      0.92      0.95       111
           3       0.93      0.95      0.94       103
           4       0.95      0.86      0.91        95
           5       0.97      0.94      0.95        97
           6       0.98      0.93      0.96       106
           7       0.89      0.88      0.88        97
           8       0.95      0.89      0.92        87
           9       0.94      0.88      0.91       112

    accuracy                           0.92      1000
   macro avg       0.93      0.92      0.92      1000
weighted avg       0.93      0.92      0.93      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_60x70.txt 3 MI 
Loading data...
Spliting data...
Using n_neighbors=3
Using metric=minkowski
Fitting knn
Predicting...
Accuracy:  0.924
[[ 96   0   0   0   0   1   0   0   0   0]
 [  0  95   0   0   0   0   0   0   0   0]
 [  0   4 102   0   1   0   1   2   1   0]
 [  0   1   0  98   0   1   0   1   2   0]
 [  0  10   2   0  82   0   0   0   0   1]
 [  1   0   0   4   0  91   1   0   0   0]
 [  2   5   0   0   0   0  99   0   0   0]
 [  1   8   0   0   0   0   0  85   0   3]
 [  1   3   0   3   0   1   0   0  77   2]
 [  0   1   0   0   3   0   0   8   1  99]]
              precision    recall  f1-score   support

           0       0.95      0.99      0.97        97
           1       0.75      1.00      0.86        95
           2       0.98      0.92      0.95       111
           3       0.93      0.95      0.94       103
           4       0.95      0.86      0.91        95
           5       0.97      0.94      0.95        97
           6       0.98      0.93      0.96       106
           7       0.89      0.88      0.88        97
           8       0.95      0.89      0.92        87
           9       0.94      0.88      0.91       112

    accuracy                           0.92      1000
   macro avg       0.93      0.92      0.92      1000
weighted avg       0.93      0.92      0.93      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_60x70.txt 5 EU 
Loading data...
Spliting data...
Using n_neighbors=5
Using metric=euclidean
Fitting knn
Predicting...
Accuracy:  0.916
[[ 95   1   0   0   0   1   0   0   0   0]
 [  0  94   0   0   0   0   0   0   0   1]
 [  0   6 100   0   1   0   1   3   0   0]
 [  0   1   0  99   0   0   0   2   1   0]
 [  0  11   1   0  83   0   0   0   0   0]
 [  1   1   0   6   0  88   1   0   0   0]
 [  0   5   0   0   0   0 101   0   0   0]
 [  0   8   0   0   0   0   0  86   0   3]
 [  0   4   0   3   1   2   0   2  74   1]
 [  0   2   0   0   4   0   0  10   0  96]]
              precision    recall  f1-score   support

           0       0.99      0.98      0.98        97
           1       0.71      0.99      0.82        95
           2       0.99      0.90      0.94       111
           3       0.92      0.96      0.94       103
           4       0.93      0.87      0.90        95
           5       0.97      0.91      0.94        97
           6       0.98      0.95      0.97       106
           7       0.83      0.89      0.86        97
           8       0.99      0.85      0.91        87
           9       0.95      0.86      0.90       112

    accuracy                           0.92      1000
   macro avg       0.93      0.92      0.92      1000
weighted avg       0.93      0.92      0.92      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_60x70.txt 5 MA 
Loading data...
Spliting data...
Using n_neighbors=5
Using metric=manhattan
Fitting knn
Predicting...
Accuracy:  0.916
[[ 95   1   0   0   0   1   0   0   0   0]
 [  0  94   0   0   0   0   0   0   0   1]
 [  0   6 100   0   1   0   1   3   0   0]
 [  0   1   0  99   0   0   0   2   1   0]
 [  0  11   1   0  83   0   0   0   0   0]
 [  1   1   0   6   0  88   1   0   0   0]
 [  0   5   0   0   0   0 101   0   0   0]
 [  0   8   0   0   0   0   0  86   0   3]
 [  0   4   0   3   1   2   0   2  74   1]
 [  0   2   0   0   4   0   0  10   0  96]]
              precision    recall  f1-score   support

           0       0.99      0.98      0.98        97
           1       0.71      0.99      0.82        95
           2       0.99      0.90      0.94       111
           3       0.92      0.96      0.94       103
           4       0.93      0.87      0.90        95
           5       0.97      0.91      0.94        97
           6       0.98      0.95      0.97       106
           7       0.83      0.89      0.86        97
           8       0.99      0.85      0.91        87
           9       0.95      0.86      0.90       112

    accuracy                           0.92      1000
   macro avg       0.93      0.92      0.92      1000
weighted avg       0.93      0.92      0.92      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_60x70.txt 5 MI 
Loading data...
Spliting data...
Using n_neighbors=5
Using metric=minkowski
Fitting knn
Predicting...
Accuracy:  0.916
[[ 95   1   0   0   0   1   0   0   0   0]
 [  0  94   0   0   0   0   0   0   0   1]
 [  0   6 100   0   1   0   1   3   0   0]
 [  0   1   0  99   0   0   0   2   1   0]
 [  0  11   1   0  83   0   0   0   0   0]
 [  1   1   0   6   0  88   1   0   0   0]
 [  0   5   0   0   0   0 101   0   0   0]
 [  0   8   0   0   0   0   0  86   0   3]
 [  0   4   0   3   1   2   0   2  74   1]
 [  0   2   0   0   4   0   0  10   0  96]]
              precision    recall  f1-score   support

           0       0.99      0.98      0.98        97
           1       0.71      0.99      0.82        95
           2       0.99      0.90      0.94       111
           3       0.92      0.96      0.94       103
           4       0.93      0.87      0.90        95
           5       0.97      0.91      0.94        97
           6       0.98      0.95      0.97       106
           7       0.83      0.89      0.86        97
           8       0.99      0.85      0.91        87
           9       0.95      0.86      0.90       112

    accuracy                           0.92      1000
   macro avg       0.93      0.92      0.92      1000
weighted avg       0.93      0.92      0.92      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_99x81.txt 1 EU 
Loading data...
Spliting data...
Using n_neighbors=1
Using metric=euclidean
Fitting knn
Predicting...
Accuracy:  0.928
[[ 95   0   0   0   0   1   1   0   0   0]
 [  0  93   0   0   0   1   0   0   0   1]
 [  0   1 103   1   0   0   0   4   1   1]
 [  0   1   0  98   0   1   0   0   3   0]
 [  0   8   0   0  83   1   1   0   0   2]
 [  2   0   0   5   0  89   1   0   0   0]
 [  1   5   0   0   0   0 100   0   0   0]
 [  0   3   1   0   1   0   0  88   0   4]
 [  0   3   0   1   1   2   0   1  79   0]
 [  0   1   0   0   2   0   0   9   0 100]]
              precision    recall  f1-score   support

           0       0.97      0.98      0.97        97
           1       0.81      0.98      0.89        95
           2       0.99      0.93      0.96       111
           3       0.93      0.95      0.94       103
           4       0.95      0.87      0.91        95
           5       0.94      0.92      0.93        97
           6       0.97      0.94      0.96       106
           7       0.86      0.91      0.88        97
           8       0.95      0.91      0.93        87
           9       0.93      0.89      0.91       112

    accuracy                           0.93      1000
   macro avg       0.93      0.93      0.93      1000
weighted avg       0.93      0.93      0.93      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_99x81.txt 1 MA 
Loading data...
Spliting data...
Using n_neighbors=1
Using metric=manhattan
Fitting knn
Predicting...
Accuracy:  0.928
[[ 95   0   0   0   0   1   1   0   0   0]
 [  0  93   0   0   0   1   0   0   0   1]
 [  0   1 103   1   0   0   0   4   1   1]
 [  0   1   0  98   0   1   0   0   3   0]
 [  0   8   0   0  83   1   1   0   0   2]
 [  2   0   0   5   0  89   1   0   0   0]
 [  1   5   0   0   0   0 100   0   0   0]
 [  0   3   1   0   1   0   0  88   0   4]
 [  0   3   0   1   1   2   0   1  79   0]
 [  0   1   0   0   2   0   0   9   0 100]]
              precision    recall  f1-score   support

           0       0.97      0.98      0.97        97
           1       0.81      0.98      0.89        95
           2       0.99      0.93      0.96       111
           3       0.93      0.95      0.94       103
           4       0.95      0.87      0.91        95
           5       0.94      0.92      0.93        97
           6       0.97      0.94      0.96       106
           7       0.86      0.91      0.88        97
           8       0.95      0.91      0.93        87
           9       0.93      0.89      0.91       112

    accuracy                           0.93      1000
   macro avg       0.93      0.93      0.93      1000
weighted avg       0.93      0.93      0.93      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_99x81.txt 1 MI 
Loading data...
Spliting data...
Using n_neighbors=1
Using metric=minkowski
Fitting knn
Predicting...
Accuracy:  0.928
[[ 95   0   0   0   0   1   1   0   0   0]
 [  0  93   0   0   0   1   0   0   0   1]
 [  0   1 103   1   0   0   0   4   1   1]
 [  0   1   0  98   0   1   0   0   3   0]
 [  0   8   0   0  83   1   1   0   0   2]
 [  2   0   0   5   0  89   1   0   0   0]
 [  1   5   0   0   0   0 100   0   0   0]
 [  0   3   1   0   1   0   0  88   0   4]
 [  0   3   0   1   1   2   0   1  79   0]
 [  0   1   0   0   2   0   0   9   0 100]]
              precision    recall  f1-score   support

           0       0.97      0.98      0.97        97
           1       0.81      0.98      0.89        95
           2       0.99      0.93      0.96       111
           3       0.93      0.95      0.94       103
           4       0.95      0.87      0.91        95
           5       0.94      0.92      0.93        97
           6       0.97      0.94      0.96       106
           7       0.86      0.91      0.88        97
           8       0.95      0.91      0.93        87
           9       0.93      0.89      0.91       112

    accuracy                           0.93      1000
   macro avg       0.93      0.93      0.93      1000
weighted avg       0.93      0.93      0.93      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_99x81.txt 3 EU 
Loading data...
Spliting data...
Using n_neighbors=3
Using metric=euclidean
Fitting knn
Predicting...
Accuracy:  0.919
[[ 96   0   0   0   0   1   0   0   0   0]
 [  0  95   0   0   0   0   0   0   0   0]
 [  0   6  99   1   1   0   1   3   0   0]
 [  0   1   0  99   0   1   0   1   1   0]
 [  0  10   2   0  81   0   0   0   0   2]
 [  1   1   0   4   0  90   1   0   0   0]
 [  1   5   0   0   0   0 100   0   0   0]
 [  1   9   0   0   0   0   0  84   0   3]
 [  1   4   0   2   0   1   0   1  77   1]
 [  0   1   0   0   3   0   0   9   1  98]]
              precision    recall  f1-score   support

           0       0.96      0.99      0.97        97
           1       0.72      1.00      0.84        95
           2       0.98      0.89      0.93       111
           3       0.93      0.96      0.95       103
           4       0.95      0.85      0.90        95
           5       0.97      0.93      0.95        97
           6       0.98      0.94      0.96       106
           7       0.86      0.87      0.86        97
           8       0.97      0.89      0.93        87
           9       0.94      0.88      0.91       112

    accuracy                           0.92      1000
   macro avg       0.93      0.92      0.92      1000
weighted avg       0.93      0.92      0.92      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_99x81.txt 3 MA 
Loading data...
Spliting data...
Using n_neighbors=3
Using metric=manhattan
Fitting knn
Predicting...
Accuracy:  0.919
[[ 96   0   0   0   0   1   0   0   0   0]
 [  0  95   0   0   0   0   0   0   0   0]
 [  0   6  99   1   1   0   1   3   0   0]
 [  0   1   0  99   0   1   0   1   1   0]
 [  0  10   2   0  81   0   0   0   0   2]
 [  1   1   0   4   0  90   1   0   0   0]
 [  1   5   0   0   0   0 100   0   0   0]
 [  1   9   0   0   0   0   0  84   0   3]
 [  1   4   0   2   0   1   0   1  77   1]
 [  0   1   0   0   3   0   0   9   1  98]]
              precision    recall  f1-score   support

           0       0.96      0.99      0.97        97
           1       0.72      1.00      0.84        95
           2       0.98      0.89      0.93       111
           3       0.93      0.96      0.95       103
           4       0.95      0.85      0.90        95
           5       0.97      0.93      0.95        97
           6       0.98      0.94      0.96       106
           7       0.86      0.87      0.86        97
           8       0.97      0.89      0.93        87
           9       0.94      0.88      0.91       112

    accuracy                           0.92      1000
   macro avg       0.93      0.92      0.92      1000
weighted avg       0.93      0.92      0.92      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_99x81.txt 3 MI 
Loading data...
Spliting data...
Using n_neighbors=3
Using metric=minkowski
Fitting knn
Predicting...
Accuracy:  0.919
[[ 96   0   0   0   0   1   0   0   0   0]
 [  0  95   0   0   0   0   0   0   0   0]
 [  0   6  99   1   1   0   1   3   0   0]
 [  0   1   0  99   0   1   0   1   1   0]
 [  0  10   2   0  81   0   0   0   0   2]
 [  1   1   0   4   0  90   1   0   0   0]
 [  1   5   0   0   0   0 100   0   0   0]
 [  1   9   0   0   0   0   0  84   0   3]
 [  1   4   0   2   0   1   0   1  77   1]
 [  0   1   0   0   3   0   0   9   1  98]]
              precision    recall  f1-score   support

           0       0.96      0.99      0.97        97
           1       0.72      1.00      0.84        95
           2       0.98      0.89      0.93       111
           3       0.93      0.96      0.95       103
           4       0.95      0.85      0.90        95
           5       0.97      0.93      0.95        97
           6       0.98      0.94      0.96       106
           7       0.86      0.87      0.86        97
           8       0.97      0.89      0.93        87
           9       0.94      0.88      0.91       112

    accuracy                           0.92      1000
   macro avg       0.93      0.92      0.92      1000
weighted avg       0.93      0.92      0.92      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_99x81.txt 5 EU 
Loading data...
Spliting data...
Using n_neighbors=5
Using metric=euclidean
Fitting knn
Predicting...
Accuracy:  0.915
[[ 95   1   0   0   0   1   0   0   0   0]
 [  0  94   0   0   0   0   0   0   0   1]
 [  0   6  99   1   1   0   1   3   0   0]
 [  0   1   0 100   0   0   0   1   1   0]
 [  0  10   1   0  84   0   0   0   0   0]
 [  1   1   0   6   0  88   1   0   0   0]
 [  0   5   0   0   0   0 101   0   0   0]
 [  0   8   0   0   1   0   0  85   0   3]
 [  0   5   0   4   0   2   0   2  74   0]
 [  0   2   0   0   5   0   0  10   0  95]]
              precision    recall  f1-score   support

           0       0.99      0.98      0.98        97
           1       0.71      0.99      0.82        95
           2       0.99      0.89      0.94       111
           3       0.90      0.97      0.93       103
           4       0.92      0.88      0.90        95
           5       0.97      0.91      0.94        97
           6       0.98      0.95      0.97       106
           7       0.84      0.88      0.86        97
           8       0.99      0.85      0.91        87
           9       0.96      0.85      0.90       112

    accuracy                           0.92      1000
   macro avg       0.92      0.92      0.92      1000
weighted avg       0.93      0.92      0.92      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_99x81.txt 5 MA 
Loading data...
Spliting data...
Using n_neighbors=5
Using metric=manhattan
Fitting knn
Predicting...
Accuracy:  0.915
[[ 95   1   0   0   0   1   0   0   0   0]
 [  0  94   0   0   0   0   0   0   0   1]
 [  0   6  99   1   1   0   1   3   0   0]
 [  0   1   0 100   0   0   0   1   1   0]
 [  0  10   1   0  84   0   0   0   0   0]
 [  1   1   0   6   0  88   1   0   0   0]
 [  0   5   0   0   0   0 101   0   0   0]
 [  0   8   0   0   1   0   0  85   0   3]
 [  0   5   0   4   0   2   0   2  74   0]
 [  0   2   0   0   5   0   0  10   0  95]]
              precision    recall  f1-score   support

           0       0.99      0.98      0.98        97
           1       0.71      0.99      0.82        95
           2       0.99      0.89      0.94       111
           3       0.90      0.97      0.93       103
           4       0.92      0.88      0.90        95
           5       0.97      0.91      0.94        97
           6       0.98      0.95      0.97       106
           7       0.84      0.88      0.86        97
           8       0.99      0.85      0.91        87
           9       0.96      0.85      0.90       112

    accuracy                           0.92      1000
   macro avg       0.92      0.92      0.92      1000
weighted avg       0.93      0.92      0.92      1000


C:\Projetos\ml-laboratorio-01>py knn.py features_99x81.txt 5 MI 
Loading data...
Spliting data...
Using n_neighbors=5
Using metric=minkowski
Fitting knn
Predicting...
Accuracy:  0.915
[[ 95   1   0   0   0   1   0   0   0   0]
 [  0  94   0   0   0   0   0   0   0   1]
 [  0   6  99   1   1   0   1   3   0   0]
 [  0   1   0 100   0   0   0   1   1   0]
 [  0  10   1   0  84   0   0   0   0   0]
 [  1   1   0   6   0  88   1   0   0   0]
 [  0   5   0   0   0   0 101   0   0   0]
 [  0   8   0   0   1   0   0  85   0   3]
 [  0   5   0   4   0   2   0   2  74   0]
 [  0   2   0   0   5   0   0  10   0  95]]
              precision    recall  f1-score   support

           0       0.99      0.98      0.98        97
           1       0.71      0.99      0.82        95
           2       0.99      0.89      0.94       111
           3       0.90      0.97      0.93       103
           4       0.92      0.88      0.90        95
           5       0.97      0.91      0.94        97
           6       0.98      0.95      0.97       106
           7       0.84      0.88      0.86        97
           8       0.99      0.85      0.91        87
           9       0.96      0.85      0.90       112

    accuracy                           0.92      1000
   macro avg       0.92      0.92      0.92      1000
weighted avg       0.93      0.92      0.92      1000

